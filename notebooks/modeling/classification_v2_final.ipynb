{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Classification, version 2, improvements like:                                                                                                      \n",
    "                                                                                                                                   \n",
    "  1. find_common_and_unique_routes() - Identifies matching and different routes between planned vs actual execution                               \n",
    "    - Compares two route lists without using sets, analyzes route agreement between predictions and actuals                                                                                    \n",
    "  2. get_positions() - Extracts location positions/indices from route sequences                                                                   \n",
    "    - Creates position mapping for each location ID, enables detailed position analysis within routes                                                                                            \n",
    "                                                                                                                                    \n",
    "  3. Detailed prediction categorization - Expanded breakdown of model predictions                                                                 \n",
    "                                                                      \n",
    "  4. Model comparison framework - Side-by-side comparison of different models                                                                     \n",
    "    - Analyzes which models correctly predict what                                                                                                \n",
    "    - Identifies common failure patterns                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "  ---                                                                                                                                             \n",
    "  Summary: V2 is a refinement of V1 with better route analysis tools (fix that metrics depends on order of the same locations and TW are included) and more granular prediction analysis, focusing on understanding where models succeed/fail rather than major architectural changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stops = pd.read_csv('data/uni_molde_v3.csv', sep=';')\n",
    "\n",
    "data_stops\n",
    "data_stops.loc[data_stops['stop_completed_at'].isna(), 'stop_completed_at'] = \"-1\"\n",
    "data_stops.loc[data_stops['stop_arrived_at'].isna(), 'stop_arrived_at'] = \"-1\"\n",
    "\n",
    "print(data_stops.isnull().sum())\n",
    "\n",
    "\n",
    "sorted_data_stops = data_stops.sort_values(by='stop_dispatched_at', ascending=True)\n",
    "sorted_data_stops = sorted_data_stops.reset_index(drop=True)\n",
    "sorted_data_stops['day_of_week'] = pd.to_datetime(sorted_data_stops['stop_dispatched_at']).dt.day_name()\n",
    "sorted_data_stops['date'] = pd.to_datetime(sorted_data_stops['stop_dispatched_at']).dt.date\n",
    "\n",
    "#clustering\n",
    "locations_df = sorted_data_stops[['current_lat', 'current_lng']]\n",
    "kmeans = KMeans(n_clusters=5000, random_state=42)\n",
    "kmeans.fit(locations_df)\n",
    "sorted_data_stops['cluster'] = kmeans.labels_ + 1\n",
    "\n",
    "sorted_data_stops['location_id_craft'] = sorted_data_stops.groupby(['current_lat', 'current_lng']).ngroup()+1\n",
    "with open('output.txt', 'w') as f:\n",
    "    print(sorted_data_stops.to_string(), file=f)\n",
    "print('number of groups', sorted_data_stops['location_id_craft'].nunique())\n",
    "\n",
    "# data_stops_day= sorted_data_stops[sorted_data_stops['day_of_week'] == \"Wednesday\"]\n",
    "grouped_df = sorted_data_stops.groupby('driver_workday_id')[['driver_id', 'location_type_id', 'address_id', 'location_id','stop_dispatched_at', 'stop_arrived_at', 'stop_earliest', 'stop_latest', 'current_lat', 'current_lng', 'stop_completed_at', 'cluster', 'location_id_craft','day_of_week', 'date', 'location_is_depot']].apply(lambda x: pd.Series({\n",
    "    'driver_id': x['driver_id'].tolist(),\n",
    "    'location_type_id': x['location_type_id'].tolist(),\n",
    "    'planned_route_location': x['location_id'].tolist(),\n",
    "    'stop_dispatched_at': x['stop_dispatched_at'].tolist(),\n",
    "    'stop_arrived_at': x['stop_arrived_at'].tolist(),\n",
    "    'stop_earliest': x['stop_earliest'].tolist(),\n",
    "    'stop_latest': x['stop_latest'].tolist(),\n",
    "    'current_lat': x['current_lat'].tolist(),\n",
    "    'current_lng': x['current_lng'].tolist(),\n",
    "    'stop_completed_at': x['stop_completed_at'].tolist(),\n",
    "    'planned_route_cluster': x['cluster'].tolist(),\n",
    "    'planned_route_craft': x['location_id_craft'].tolist(),\n",
    "    'day_of_week': x['day_of_week'].tolist(),\n",
    "    'location_is_depot': x['location_is_depot'].tolist(),\n",
    "    'date': x['date'].tolist()\n",
    "})).reset_index()\n",
    "grouped_df\n",
    "# grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "\n",
    "# Function to calculate distance between two coordinates\n",
    "def calculate_distance(row):\n",
    "    distances = []\n",
    "    for i in range(len(row['planned_route_craft'])-1):\n",
    "        coords_1 = (sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['planned_route_craft'][i], ['current_lat']].values[0][0],\n",
    "                     sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['planned_route_craft'][i], ['current_lng']].values[0][0])\n",
    "        coords_2 = (sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['planned_route_craft'][i+1], ['current_lat']].values[0][0],\n",
    "                     sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['planned_route_craft'][i+1], ['current_lng']].values[0][0])\n",
    "        distances.append(geodesic(coords_1, coords_2).miles)\n",
    "    return distances\n",
    "\n",
    "def calculate_distance_actual(row):\n",
    "    distances = []\n",
    "    for i in range(len(row['actual_route_location'])-1):\n",
    "        coords_1 = (sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['actual_route_location'][i], ['current_lat']].values[0][0],\n",
    "                     sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['actual_route_location'][i], ['current_lng']].values[0][0])\n",
    "        coords_2 = (sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['actual_route_location'][i+1], ['current_lat']].values[0][0],\n",
    "                     sorted_data_stops.loc[sorted_data_stops['location_id_craft'] == row['actual_route_location'][i+1], ['current_lng']].values[0][0])\n",
    "        distances.append(geodesic(coords_1, coords_2).miles)\n",
    "    return distances\n",
    "\n",
    "# Create a new column 'distance_route' in 'final_routes'\n",
    "grouped_df['distance_route'] = grouped_df.apply(calculate_distance, axis=1)\n",
    "grouped_df['total_distance_planned'] = grouped_df['distance_route'].apply(sum)\n",
    "# total_sum_distance = grouped_df['distance_route'].sum()\n",
    "# grouped_df['total_distance'] = total_sum_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20692"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df['total_distance_planned'] = grouped_df['distance_route'].apply(sum)\n",
    "routes = grouped_df[grouped_df.apply(lambda row: max(row['stop_dispatched_at']) < min(row['stop_completed_at']), axis=1)]\n",
    "routes = routes.reset_index(drop=True)\n",
    "len(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index_routes_with_na = []\n",
    "for i in range(len(routes)):\n",
    "    row = routes.iloc[i]\n",
    "    if \"-1\" in row['stop_arrived_at']:\n",
    "        index_routes_with_na.append(i)\n",
    "print(\"The number of routes where one value is NA(arrived time)\", len(index_routes_with_na))\n",
    "print(index_routes_with_na)\n",
    "routes = routes.drop(index_routes_with_na)\n",
    "routes.reset_index(drop=True)\n",
    "#\n",
    "print(len(routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#check if it is the same driver in the route\n",
    "routes['day_of_week'] = routes['stop_arrived_at'].apply(lambda x: [pd.to_datetime(dt).day_name() for dt in x])\n",
    "\n",
    "def get_mode(x):\n",
    "    return pd.Series(x).mode().iloc[0] if not pd.Series(x).mode().empty else np.nan\n",
    "\n",
    "for i in routes['driver_id']:\n",
    "    if not all(x == i[0] for x in i):\n",
    "            print('Not the same driver in the route')\n",
    "routes['driver_id'] = routes['driver_id'].apply(lambda x : x[0])\n",
    "\n",
    "routes['day_of_week'] = routes['day_of_week'].apply(get_mode)\n",
    "routes['date'] = routes['date'].apply(get_mode)\n",
    "\n",
    "routes['date'] = pd.to_datetime(routes['date'])\n",
    "routes['last_two_weeks_count'] = routes.apply(lambda row:\n",
    "                                      routes[(routes['driver_id'] == row['driver_id']) &\n",
    "                                         (row['date'] - routes['date']).dt.days.between(-14, 0)].shape[0],\n",
    "                                      axis=1)\n",
    "routes = routes[(routes['date'] < '2023-12-21') | (routes['date'] > '2024-01-14')]\n",
    "routes['location_type_id'] = routes['location_type_id'].apply(lambda x: [0 if i == 1 else 1 for i in x])\n",
    "routes['location_is_depot'] = routes['location_is_depot'].apply(lambda x: [int(value) for value in x])\n",
    "\n",
    "routes = routes[routes['planned_route_craft'].apply(lambda x: len(x) > 2)]\n",
    "routes = routes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18562"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_actual_route(df, column):\n",
    "    res_col = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        sorted_dates = sorted(row['stop_arrived_at'])\n",
    "        mapping = {}\n",
    "        for i, date in enumerate(row['stop_arrived_at']):\n",
    "            mapping[date] = row[column][i]\n",
    "        res_val = [mapping[sorted_dates[i]] for i in range(len(sorted_dates))]\n",
    "        res_col.append(res_val)\n",
    "    return res_col\n",
    "\n",
    "def create_actual_route_type(df, column):\n",
    "    res_col = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        sorted_dates = sorted(row['stop_arrived_at'])\n",
    "        mapping = {}\n",
    "        for i, date in enumerate(row['stop_arrived_at']):\n",
    "            mapping[date] = row['location_type_id'][i]\n",
    "        res_val = [mapping[sorted_dates[i]] for i in range(len(sorted_dates))]\n",
    "        res_col.append(res_val)\n",
    "    return res_col\n",
    "\n",
    "routes['actual_route_location'] = create_actual_route(routes, 'planned_route_craft')\n",
    "routes['actual_route_type'] = create_actual_route_type(routes, 'planned_route_craft')\n",
    "routes['distance_actual_route'] = routes.apply(calculate_distance_actual, axis=1)\n",
    "routes['total_distance_actual'] = routes['distance_actual_route'].apply(sum)\n",
    "routes['difference_distance'] = (routes['total_distance_actual'] - routes['total_distance_planned'])/routes['total_distance_planned']\n",
    "\n",
    "#remove all the routes with length <= 2\n",
    "routes = routes[routes['planned_route_craft'].apply(lambda x: len(x) > 2)]\n",
    "routes = routes.reset_index(drop=True)\n",
    "\n",
    "len(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "routes = routes.reset_index(drop=True)\n",
    "more_than_one_1 = routes[routes['location_is_depot'].apply(lambda x: x.count(True) > 1)]\n",
    "len(more_than_one_1), len(routes)\n",
    "\n",
    "routes['actual_route_unique'] = create_actual_route(routes, 'planned_route_location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "planned_routes = routes[['planned_route_craft', 'actual_route_location', 'driver_id', 'day_of_week', 'last_two_weeks_count', 'location_type_id', 'stop_arrived_at', 'stop_earliest', 'stop_latest', 'current_lat', 'current_lng', 'difference_distance', 'distance_route', 'distance_actual_route', 'location_is_depot', 'location_type_id', 'date', 'planned_route_location', 'actual_route_unique']]\n",
    "actual_routes = routes['actual_route_location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18562, 18562)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planned_routes_list = planned_routes['planned_route_craft'].tolist()\n",
    "actual_routes_list = actual_routes.tolist()\n",
    "\n",
    "# filtered_rows = []\n",
    "#\n",
    "# for row in actual_routes_list:\n",
    "#     if row not in planned_routes_list:\n",
    "#         filtered_rows.append(row)\n",
    "\n",
    "#duplicated removed\n",
    "# planned_routes_list = [array for i, array in enumerate(planned_routes_list) if array not in planned_routes_list[:i]]\n",
    "# actual_routes_list = [array for i, array in enumerate(filtered_rows) if array not in filtered_rows[:i]]\n",
    "len(planned_routes_list),len(actual_routes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Edit Distance\n",
    "\n",
    "def minDistance(word1, word2) -> int:\n",
    "    m = len(word1)\n",
    "    n = len(word2)\n",
    "    # dp[i][j] := min # Of operations to convert word1[0..i) to word2[0..j)\n",
    "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "      dp[i][0] = i\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "      dp[0][j] = j\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "      for j in range(1, n + 1):\n",
    "        if word1[i - 1] == word2[j - 1]:\n",
    "          dp[i][j] = dp[i - 1][j - 1]\n",
    "        else:\n",
    "          dp[i][j] = min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1\n",
    "\n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Route quality score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_route_quality_score(planned_ranks, actual_ranks):\n",
    "    # Calculate sum of absolute differences in ranks\n",
    "    sum_of_differences = sum(abs(actual_ranks.index(x) - planned_ranks.index(x)) for x in planned_ranks)\n",
    "\n",
    "    # Calculate max possible difference\n",
    "    max_possible_difference = sum([abs(2 * i - (len(planned_ranks) + 1)) for i in range(1, len(planned_ranks) + 1)])\n",
    "\n",
    "    # Calculate route quality score\n",
    "    route_quality_score = 1 - (sum_of_differences / max_possible_difference)\n",
    "    return route_quality_score\n",
    "\n",
    "    # return route_quality_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_positions(seq):\n",
    "    d = defaultdict(lambda: [])\n",
    "    for idx, item in enumerate(seq):\n",
    "        d[item].append(idx)\n",
    "    return d\n",
    "\n",
    "def calculate_route_quality_score(planned_ranks, actual_ranks):\n",
    "    sum_of_differences = 0\n",
    "    planned = get_positions(planned_ranks)\n",
    "    actual = get_positions(actual_ranks)\n",
    "    for key in planned:\n",
    "        for i in range(len(planned[key])):\n",
    "            sum_of_differences += abs(planned[key][i] - actual[key][i])\n",
    "    max_possible_difference = sum([abs(2 * i - (len(planned_ranks) + 1)) for i in range(1, len(planned_ranks) + 1)])\n",
    "\n",
    "    # Calculate route quality score\n",
    "    route_quality_score = 1 - (sum_of_differences / max_possible_difference)\n",
    "    return route_quality_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For each driver-day, we consider only the planned route. For each planned route we calculate how much it deviates from the actual route (e.g., use some form of edit distance - see https://link.springer.com/article/10.1007/s10732-006-9001-3?), which is then normalized (divide by edit distance, or number of visits or something?) to the interval [0, 1]. Then, a planned route is good if this distance (between planned and actual) is less than a certain threshold and otherwise it is bad. This becomes the label (bad/good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "completed_routes_df = pd.DataFrame(columns=['planned_route_craft', 'actual_route_location', 'driver_id', 'day_of_week', 'distance_route', 'distance_actual_route', 'last_two_weeks_count', 'stop_arrived_at', 'stop_earliest', 'stop_latest', 'current_lat', 'current_lng', 'location_type_id', 'location_is_depot', 'date'])\n",
    "uncompleted_routes_df = pd.DataFrame(columns=['planned_route_craft', 'actual_route_location', 'driver_id', 'day_of_week', 'distance_route', 'distance_actual_route', 'last_two_weeks_count', 'stop_arrived_at', 'stop_earliest', 'stop_latest', 'current_lat', 'current_lng', 'location_type_id', 'location_is_depot', 'date'])\n",
    "#11700795\n",
    "scores = []\n",
    "edit_distances = []\n",
    "completed_routes_list = []\n",
    "uncompleted_routes_list = []\n",
    "for i in range(len(planned_routes_list)):\n",
    "    editDistance = minDistance(planned_routes_list[i], actual_routes_list[i]) / len(planned_routes_list[i])\n",
    "    score = calculate_route_quality_score(planned_routes_list[i], actual_routes_list[i])\n",
    "    scores.append(score)\n",
    "    edit_distances.append(editDistance)\n",
    "\n",
    "    #if score >= 0.85 and editDistance <= 0.3 and planned_routes['difference_distance'].iloc[i] <= 0.03: main\n",
    "    # if editDistance > 0.05 and score < 0.95 and planned_routes['difference_distance'].iloc[i] > 0.01:\n",
    "\n",
    "    # if editDistance <= 0 and score >= 1 and planned_routes['difference_distance'].iloc[i] <= 0:\n",
    "    if score >= 0.85 and editDistance <= 0.3 and planned_routes['difference_distance'].iloc[i] <= 0.03:\n",
    "        completed_routes_list.append(planned_routes.iloc[i].to_dict())\n",
    "    else:\n",
    "        uncompleted_routes_list.append(planned_routes.iloc[i].to_dict())\n",
    "\n",
    "# Convert the lists to DataFrames\n",
    "completed_routes_df = pd.DataFrame(completed_routes_list)\n",
    "uncompleted_routes_df = pd.DataFrame(uncompleted_routes_list)\n",
    "\n",
    "print(len(completed_routes_df), len(uncompleted_routes_df))\n",
    "completed_routes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "scores = [v for v in edit_distances if v != 0]\n",
    "# edit_distances = pd.DataFrame(scores, columns=['Edit Distances'])\n",
    "# edit_distances.describe()\n",
    "# distances_without_outl = routes[(routes['difference_distance'] < 2) & (routes['difference_distance'] > 0)]['difference_distance']\n",
    "\n",
    "# print(distances_without_outl)\n",
    "\n",
    "sns.set(style='white')\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.kdeplot(data=scores, color='black', linewidth=1, fill=False, bw_adjust=0.5)\n",
    "\n",
    "plt.xlabel('EDS Value', fontsize=26)\n",
    "plt.ylabel('Probability density', fontsize=26)\n",
    "plt.tick_params(axis='both', which='major', labelsize=24)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=24)\n",
    "\n",
    "# plt.xlim(-0.1, 2)\n",
    "\n",
    "ax = plt.gca()\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('black')\n",
    "    spine.set_linewidth(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "scores = [v for v in scores if v != 1]\n",
    "scores = pd.DataFrame(scores, columns=['Score'])\n",
    "# # scores.describe()\n",
    "#\n",
    "# edit_distances = [v for v in edit_distances if v != 0]\n",
    "# edit_distances = pd.DataFrame(edit_distances, columns=['Edit Distances'])\n",
    "# edit_distances.describe()\n",
    "\n",
    "# routes[routes['difference_distance'] > 0]['difference_distance'].describe()\n",
    "\n",
    "\n",
    "# Set style and context for publication-ready figures\n",
    "sns.set(style='white')\n",
    "\n",
    "# Create a larger figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list(\n",
    "    'green_amber_red', [(0, 'green'), (0.1, 'yellow'), (0.4, 'orange'), (1, 'red')]\n",
    ")\n",
    "\n",
    "# Normalize the data for color mapping\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=2)\n",
    "\n",
    "# Calculate the KDE\n",
    "kde = sns.kdeplot(scores, fill=False, bw_adjust=0.5)\n",
    "x, y = kde.get_lines()[0].get_data()\n",
    "\n",
    "# Clear the plot to redraw with gradient\n",
    "plt.clf()\n",
    "\n",
    "# Set style and context for publication-ready figures\n",
    "sns.set(style='white')\n",
    "\n",
    "# Create a larger figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot with gradient color\n",
    "# for i in range(len(x) - 1):\n",
    "#     plt.plot(x[i:i+2], y[i:i+2], color=cmap(norm(np.mean(x[i:i+2]))), linewidth=2)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.xlabel('DDS', fontsize=26)\n",
    "plt.ylabel('Probability density', fontsize=20)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)  # Major ticks\n",
    "plt.tick_params(axis='both', which='minor', labelsize=20)  # Minor ticks (if any)\n",
    "\n",
    "ax = plt.gca()  # Get the current axes\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor('black')  # Color of the border\n",
    "    spine.set_linewidth(0.5)  # Thickness of the border\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(False)  # Remove gridlines\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drivers_dic = {}\n",
    "k = 1\n",
    "for driver in completed_routes_df['driver_id']:\n",
    "    if driver not in drivers_dic:\n",
    "        drivers_dic[driver] = k\n",
    "        k += 1\n",
    "print('Total number of drivers', len(drivers_dic))\n",
    "total_drivers = len(drivers_dic)\n",
    "encoding_drivers = []\n",
    "for driver in completed_routes_df['driver_id']:\n",
    "    encoding_drivers.append(drivers_dic[driver])\n",
    "#\n",
    "completed_routes_df['driver_id_sorted'] = encoding_drivers\n",
    "# final_routes = pd.concat([final_routes, pd.get_dummies(final_routes['driver_id_sorted'], prefix='encoding_drivers')], axis=1)\n",
    "completed_routes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows on Sunday: 22\n"
     ]
    }
   ],
   "source": [
    "sunday_count = completed_routes_df[completed_routes_df[\"day_of_week\"] == \"Sunday\"].shape[0]\n",
    "print(f\"Number of rows on Sunday: {sunday_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_routes = pd.DataFrame({\n",
    "    'routes': completed_routes_df['planned_route_craft'].tolist() + uncompleted_routes_df['planned_route_craft'].tolist(),\n",
    "    'actual_routes': completed_routes_df['actual_route_location'].tolist() + uncompleted_routes_df['actual_route_location'].tolist(),\n",
    "    'driver_id': completed_routes_df['driver_id'].tolist() +  uncompleted_routes_df['driver_id'].tolist(),\n",
    "    'distance_route': completed_routes_df['distance_route'].tolist() + uncompleted_routes_df['distance_route'].tolist(),\n",
    "    'distance_actual_route': completed_routes_df['distance_actual_route'].tolist() + uncompleted_routes_df['distance_actual_route'].tolist(),\n",
    "    'last_two_weeks_count': completed_routes_df['last_two_weeks_count'].tolist() + uncompleted_routes_df['last_two_weeks_count'].tolist(),\n",
    "    'current_lat': completed_routes_df['current_lat'].tolist() + uncompleted_routes_df['current_lat'].tolist(),\n",
    "    'current_lng': completed_routes_df['current_lng'].tolist() + uncompleted_routes_df['current_lng'].tolist(),\n",
    "    'day_of_week': completed_routes_df['day_of_week'].tolist() + uncompleted_routes_df['day_of_week'].tolist(),\n",
    "    'date': completed_routes_df['date'].tolist() + uncompleted_routes_df['date'].tolist(),\n",
    "    'location_is_depot': completed_routes_df['location_is_depot'].tolist() + uncompleted_routes_df['location_is_depot'].tolist(),\n",
    "    'location_type_id': completed_routes_df['location_type_id'].tolist() + uncompleted_routes_df['location_type_id'].tolist(),\n",
    "    'arriving_time': completed_routes_df['stop_arrived_at'].tolist() + uncompleted_routes_df['stop_arrived_at'].tolist(),\n",
    "    'label': [0] * len(completed_routes_df)  + [1] * len(uncompleted_routes_df)\n",
    "})\n",
    "final_routes['len'] = final_routes['routes'].apply(lambda x: len(x))\n",
    "final_routes\n",
    "\n",
    "# [0] * len(artificial_planned_routes)\n",
    "# artificial_planned_routes['distance_route'].tolist()\n",
    "# artificial_planned_routes['driver_id'].tolist()\n",
    "# artificial_planned_routes['common_subsequence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_country(lat, lng):\n",
    "    if 57.5 <= lat <= 71.2 and 4.0 <= lng <= 31.0:\n",
    "        return 0  # Norway\n",
    "    elif 54.5 <= lat <= 57.8 and 8.0 <= lng <= 15.0:\n",
    "        return 1  # Denmark\n",
    "    else:\n",
    "        return 1\n",
    "final_routes['country_flag'] = final_routes.apply(lambda row: determine_country(row['current_lat'][0], row['current_lng'][0]), axis=1)\n",
    "\n",
    "max([len(i) for i in final_routes['routes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10704\n"
     ]
    }
   ],
   "source": [
    "#create dictionary and encode to smaller unique numbers\n",
    "locations_dic = {}\n",
    "location_count = {}\n",
    "k = 1\n",
    "for row in final_routes['routes']:\n",
    "   for location in row:\n",
    "       if location not in locations_dic:\n",
    "           locations_dic[location] = k\n",
    "           k += 1\n",
    "k = 1\n",
    "print(len(locations_dic))\n",
    "\n",
    "for row in final_routes['routes']:\n",
    "   for location in row:\n",
    "       if location not in location_count:\n",
    "            location_count[location] = 1\n",
    "       else:\n",
    "            location_count[location] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of drivers 395\n",
      "correlation 0.31512808794486846\n",
      "correlation 36\n"
     ]
    }
   ],
   "source": [
    "drivers_dic = {}\n",
    "k = 1\n",
    "for driver in final_routes['driver_id']:\n",
    "    if driver not in drivers_dic:\n",
    "        drivers_dic[driver] = k\n",
    "        k += 1\n",
    "print('Total number of drivers', len(drivers_dic))\n",
    "total_drivers = len(drivers_dic)\n",
    "encoding_drivers = []\n",
    "for driver in final_routes['driver_id']:\n",
    "    encoding_drivers.append(drivers_dic[driver])\n",
    "#\n",
    "final_routes['driver_id_sorted'] = encoding_drivers\n",
    "final_routes['day_of_week_encoded'] = pd.Categorical(final_routes['day_of_week']).codes+1\n",
    "\n",
    "def encode_day_of_week(row):\n",
    "    a = np.zeros((36, 7), dtype=int)\n",
    "    route_len = row['len']\n",
    "    day_encoded = row['day_of_week_encoded']\n",
    "    for i in range(36 - route_len, len(a)):\n",
    "        a[i][day_encoded-1] = 1\n",
    "    return a\n",
    "\n",
    "def encode_day_of_week_simple(row):\n",
    "    a = np.zeros(7, dtype=int)\n",
    "    day_encoded = row['day_of_week_encoded']\n",
    "    a[day_encoded - 1] = 1\n",
    "    return a\n",
    "\n",
    "final_routes['experience_feature'] = final_routes.apply(lambda x: x['len'] * [x['last_two_weeks_count']], axis = 1)\n",
    "final_routes['len_feature'] = final_routes.apply(lambda x: x['len'] * [x['len']], axis = 1)\n",
    "final_routes['driver_id_feature'] = final_routes.apply(lambda x: x['len'] * [x['driver_id_sorted']], axis = 1)\n",
    "final_routes['country_flag_feature'] = final_routes.apply(lambda x: x['len'] * [x['country_flag']], axis = 1)\n",
    "final_routes['day_of_week_feature'] = final_routes.apply(encode_day_of_week, axis = 1)\n",
    "final_routes['day_of_week_encoded_ext'] = final_routes.apply(encode_day_of_week_simple, axis = 1)\n",
    "\n",
    "# encoding_routes = []\n",
    "# for row in final_routes['routes']:\n",
    "#     encoding_route = []\n",
    "#     for location in row:\n",
    "#         encoding_route.append(locations_dic[location])\n",
    "#     encoding_routes.append(encoding_route)\n",
    "# final_routes['routes'] = encoding_routes\n",
    "\n",
    "print('correlation', final_routes['len'].corr(final_routes['label']))\n",
    "print('correlation', max(final_routes['len']))\n",
    "# final_routes = pd.concat([final_routes, pd.get_dummies(final_routes['driver_id_sorted'], prefix='encoding_drivers')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_routes['first_arrival'] = final_routes['arriving_time'].apply(lambda x: x[0])\n",
    "\n",
    "# Convert to datetime and sort\n",
    "final_routes['first_arrival'] = pd.to_datetime(final_routes['first_arrival'])\n",
    "final_routes = final_routes.sort_values('first_arrival').reset_index(drop=True)\n",
    "\n",
    "# Drop the temporary column\n",
    "final_routes = final_routes.drop('first_arrival', axis=1)\n",
    "final_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_routes['score_cumulative_avg'] = final_routes.groupby(['driver_id_sorted', 'day_of_week'])['label'].transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "final_routes['score_cumulative_driver'] = final_routes.groupby(['driver_id_sorted'])['label'].transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "final_routes['score_avg_total'] = final_routes['label'].expanding().mean()\n",
    "\n",
    "final_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Average benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# result = final_routes.groupby('driver_id_sorted')[['driver_id_sorted', 'score']].apply(\n",
    "#     lambda x: pd.Series({'count': len(x), 'score': x['score'].tolist()})\n",
    "# ).reset_index()\n",
    "#\n",
    "# sorted_result = result.sort_values(by='count', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_predictions(df, scores_dict):\n",
    "    def predict(row):\n",
    "        # Try to get the score from the main dictionary\n",
    "        label = scores_dict.get((row['driver_id_sorted'], row['day_of_week']))\n",
    "        return label\n",
    "        # If not found, fall back to the driver-only dictionary\n",
    "        # if label is None:\n",
    "        #     print('1')\n",
    "        #     return 0.5\n",
    "        # else:\n",
    "        #     return label\n",
    "\n",
    "    return df.apply(predict, axis=1)\n",
    "\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    quadratic_loss = log_loss(y_true, y_pred_proba)\n",
    "    brier_score = brier_score_loss(y_true, y_pred_proba)\n",
    "\n",
    "    metrics = {\n",
    "        \"acc\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"quadratic_loss\": quadratic_loss,\n",
    "        \"brier_score\": brier_score,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/mpbqwzf51p38zw2w423xp1fw0000gn/T/ipykernel_18931/1217222917.py:76: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  final_routes_split = final_routes.groupby(['driver_id_sorted', 'day_of_week']).apply(split_group).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of drivers 314\n",
      "10546\n",
      "17667\n",
      "lens 13823 2188 1656\n",
      "val_metrics {'acc': 0.7143510054844607, 'precision': 0.7315541601255887, 'recall': 0.7670781893004115, 'f1': 0.7488951386098834, 'roc_auc': 0.7077939764590444, 'average_precision': 0.6905011052409561, 'quadratic_loss': 1.2720613746590246, 'brier_score': 0.19390942165158653, 'true_positive': 932, 'false_positive': 342, 'true_negative': 631, 'false_negative': 283}\n",
      "test_metrics {'acc': 0.7065217391304348, 'precision': 0.7199170124481328, 'recall': 0.7626373626373626, 'f1': 0.7406616862326574, 'roc_auc': 0.7003535338655982, 'average_precision': 0.679470394299909, 'quadratic_loss': 1.2956978793104297, 'brier_score': 0.19880618428965857, 'true_positive': 694, 'false_positive': 270, 'true_negative': 476, 'false_negative': 216}\n",
      "694 270\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def get_predictions(df, scores_dict):\n",
    "    def predict(row):\n",
    "        # Try to get the score from the main dictionary\n",
    "        label = scores_dict.get((row['driver_id_sorted'], row['day_of_week']))\n",
    "\n",
    "        # If not found, fall back to the driver-only dictionary\n",
    "        if label is None:\n",
    "            print('1')\n",
    "            return 0.5\n",
    "        else:\n",
    "            return label\n",
    "\n",
    "    return df.apply(predict, axis=1)\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    quadratic_loss = log_loss(y_true, y_pred_proba)\n",
    "    brier_score = brier_score_loss(y_true, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    metrics = {\n",
    "        \"acc\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"quadratic_loss\": quadratic_loss,\n",
    "        \"brier_score\": brier_score,\n",
    "        \"true_positive\": tp,\n",
    "        \"false_positive\": fp,\n",
    "        \"true_negative\": tn,\n",
    "        \"false_negative\": fn\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def split_group(group):\n",
    "    n = len(group)\n",
    "    if n < 4:  # Ensure at least 1 sample for train and 1 each for val and test\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate sizes for each split\n",
    "    train_size = max(int(n * 0.8), n - 4)  # Ensure at least 2 samples total for val and test\n",
    "    val_test_size = n - train_size\n",
    "\n",
    "    # Always give the extra sample to val when odd\n",
    "    val_size = (val_test_size + 1) // 2  # This will be larger when val_test_size is odd\n",
    "    test_size = val_test_size - val_size\n",
    "\n",
    "    return pd.concat([\n",
    "        group.iloc[:train_size].assign(split='train'),\n",
    "        group.iloc[train_size:train_size+val_size].assign(split='val'),\n",
    "        group.iloc[train_size+val_size:].assign(split='test')\n",
    "    ])\n",
    "\n",
    "def categorize_predictions(df, y_true, y_pred, y_pred_proba):\n",
    "    df = df.copy()\n",
    "    df['prediction_category'] = 'Unknown'\n",
    "    df.loc[(y_true == 1) & (y_pred == 1), 'prediction_category'] = 'True Positive'\n",
    "    df.loc[(y_true == 0) & (y_pred == 1), 'prediction_category'] = 'False Positive'\n",
    "    df.loc[(y_true == 1) & (y_pred == 0), 'prediction_category'] = 'False Negative'\n",
    "    df.loc[(y_true == 0) & (y_pred == 0), 'prediction_category'] = 'True Negative'\n",
    "    df['predictive_probability'] = y_pred_proba\n",
    "    return df\n",
    "\n",
    "def save_categorized_routes(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved categorized routes to {filename}\")\n",
    "\n",
    "\n",
    "final_routes_split = final_routes.groupby(['driver_id_sorted', 'day_of_week']).apply(split_group).reset_index(drop=True)\n",
    "# Separate into train, validation, and test sets\n",
    "\n",
    "drivers_dic = {}\n",
    "k = 1\n",
    "for driver in final_routes_split['driver_id_sorted']:\n",
    "    if driver not in drivers_dic:\n",
    "        drivers_dic[driver] = k\n",
    "        k += 1\n",
    "print('Total number of drivers', len(drivers_dic))\n",
    "total_drivers = len(drivers_dic)\n",
    "encoding_drivers = []\n",
    "for driver in final_routes_split['driver_id_sorted']:\n",
    "    encoding_drivers.append(drivers_dic[driver])\n",
    "#\n",
    "final_routes_split['driver_id_sorted'] = encoding_drivers\n",
    "\n",
    "locations_dic = {}\n",
    "location_count = {}\n",
    "k = 1\n",
    "for row in final_routes_split['routes']:\n",
    "   for location in row:\n",
    "       if location not in locations_dic:\n",
    "           locations_dic[location] = k\n",
    "           k += 1\n",
    "k = 1\n",
    "print(len(locations_dic))\n",
    "\n",
    "for row in final_routes_split['routes']:\n",
    "   for location in row:\n",
    "       if location not in location_count:\n",
    "            location_count[location] = 1\n",
    "       else:\n",
    "            location_count[location] += 1\n",
    "encoding_routes = []\n",
    "for row in final_routes_split['routes']:\n",
    "    encoding_route = []\n",
    "    for location in row:\n",
    "        encoding_route.append(locations_dic[location])\n",
    "    encoding_routes.append(encoding_route)\n",
    "final_routes_split['routes'] = encoding_routes\n",
    "\n",
    "print(len(final_routes_split))\n",
    "train_df = final_routes_split[final_routes_split['split'] == 'train'].drop('split', axis=1)\n",
    "val_df = final_routes_split[final_routes_split['split'] == 'val'].drop('split', axis=1)\n",
    "test_df = final_routes_split[final_routes_split['split'] == 'test'].drop('split', axis=1)\n",
    "\n",
    "print('lens', len(train_df), len(val_df), len(test_df))\n",
    "combined_df = pd.concat([train_df, val_df, test_df], axis=0)\n",
    "combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "val_y_true = val_df['label']\n",
    "average_scores_dict = train_df.groupby(['driver_id_sorted', 'day_of_week'])['score_cumulative_avg'].last().to_dict()\n",
    "average_scores_dict_driver = train_df.groupby(['driver_id_sorted'])['score_cumulative_driver'].last().to_dict()\n",
    "total_avg = train_df['score_avg_total'].iloc[-1]\n",
    "val_y_pred_proba = get_predictions(val_df, average_scores_dict)\n",
    "val_y_pred = (val_y_pred_proba.values > 0.5).astype(int)\n",
    "val_metrics = calculate_metrics(val_y_true, val_y_pred, val_y_pred_proba)\n",
    "\n",
    "# # # Calculate metrics for test set\n",
    "test_y_true = test_df['label']\n",
    "test_y_pred_proba = get_predictions(test_df, average_scores_dict)\n",
    "test_y_pred = (test_y_pred_proba.values > 0.5).astype(int)\n",
    "test_metrics = calculate_metrics(test_y_true, test_y_pred, test_y_pred_proba)\n",
    "\n",
    "# test_y_pred_proba = pd.Series([total_avg] * len(test_y_true))\n",
    "# test_y_pred = (test_y_pred_proba > 0.5).astype(int)\n",
    "# test_metrics = calculate_metrics(test_y_true, test_y_pred, test_y_pred_proba)\n",
    "\n",
    "print('val_metrics', val_metrics)\n",
    "print('test_metrics', test_metrics)\n",
    "\n",
    "test_df_group_HA = categorize_predictions(test_df, test_y_true, test_y_pred, test_y_pred_proba)\n",
    "# save_categorized_routes(test_df_categorized, 'test_routes_categorized_HA.csv')\n",
    "test_df_group_HA[test_df_group_HA['prediction_category'] == 'True Positive']['routes']\n",
    "print(len(test_df_group_HA[test_df_group_HA['prediction_category'] == 'True Positive']['routes']), len(test_df_group_HA[test_df_group_HA['prediction_category'] == 'False Positive']['routes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# After benchmark, continue model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming final_routes dataframe is available and sorted by date\n",
    "# If not, make sure to sort it by date first\n",
    "\n",
    "# Prepare the data\n",
    "rf_df = final_routes_split[['driver_id_sorted', 'day_of_week_encoded', 'label', 'split', 'routes']]\n",
    "o_day_of = pd.get_dummies(rf_df['day_of_week_encoded'], prefix='day')\n",
    "o_driver = pd.get_dummies(rf_df['driver_id_sorted'], prefix='driver')\n",
    "rf_df = pd.concat([o_day_of, o_driver, rf_df['split'], rf_df['label'], rf_df['routes']], axis=1)\n",
    "\n",
    "\n",
    "for col in rf_df.columns:\n",
    "    if col != 'split' and col != 'label' and col != 'routes':\n",
    "        rf_df[col] = rf_df[col].astype(int)\n",
    "\n",
    "train_df = rf_df[rf_df['split'] == 'train'].drop('split', axis=1)\n",
    "val_df = rf_df[rf_df['split'] == 'val'].drop('split', axis=1)\n",
    "test_df = rf_df[rf_df['split'] == 'test'].drop('split', axis=1)\n",
    "\n",
    "# Create X_train and y_train\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Create X_val and y_val (optional, but often useful)\n",
    "X_val = val_df.drop('label', axis=1)\n",
    "y_val = val_df['label']\n",
    "\n",
    "# Create X_test and y_test (optional, but often useful)\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "#\n",
    "#\n",
    "# Train the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "X_trainwr = X_train.drop('routes', axis=1)\n",
    "model.fit(X_trainwr, y_train)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    quadratic_loss = log_loss(y_true, y_pred_proba)\n",
    "    brier_score = brier_score_loss(y_true, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    metrics = {\n",
    "        \"acc\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"quadratic_loss\": quadratic_loss,\n",
    "        \"brier_score\": brier_score,\n",
    "        \"true_positive\": tp,\n",
    "        \"false_positive\": fp,\n",
    "        \"true_negative\": tn,\n",
    "        \"false_negative\": fn\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_proba = model.predict(X_val.drop('routes', axis=1))\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "val_metrics = calculate_metrics(y_val, y_val_pred, y_val_pred_proba)\n",
    "\n",
    "y_test_pred_proba = model.predict(X_test.drop('routes', axis=1))\n",
    "y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, y_test_pred_proba)\n",
    "\n",
    "print(val_metrics)\n",
    "print(test_metrics)\n",
    "\n",
    "test_df_group_RF = categorize_predictions(test_df, y_test, y_test_pred, y_test_pred_proba)\n",
    "test_df_group_RF\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df_group_RF[test_df_group_RF['prediction_category'] == 'True Positive']['routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ha_tp_routes = test_df_group_HA[test_df_group_HA['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "rf_tp_routes = test_df_group_RF[test_df_group_RF['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "\n",
    "# Convert lists to sets of tuples for comparison\n",
    "ha_tp_routes_set = set(tuple(route) for route in ha_tp_routes)\n",
    "rf_tp_routes_set = set(tuple(route) for route in rf_tp_routes)\n",
    "\n",
    "# Find non-overlapping routes\n",
    "ha_only_routes = ha_tp_routes_set - rf_tp_routes_set\n",
    "rf_only_routes = rf_tp_routes_set - ha_tp_routes_set\n",
    "\n",
    "# Convert back to lists for display\n",
    "ha_only_routes = [list(route) for route in ha_only_routes]\n",
    "rf_only_routes = [list(route) for route in rf_only_routes]\n",
    "\n",
    "print(\"Routes unique to HA model:\", len(ha_only_routes))\n",
    "print(\"Sample of HA-only routes:\", ha_only_routes[:5])\n",
    "\n",
    "print(\"\\nRoutes unique to RF model:\", len(rf_only_routes))\n",
    "print(\"Sample of RF-only routes:\", rf_only_routes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming final_routes dataframe and relevant imports are available\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.drop('routes', axis=1).values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val.drop('routes', axis=1).values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test.drop('routes', axis=1).values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = SimpleNN(X_train.shape[1]-1)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training and validation loop\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    y_true = y_test_tensor\n",
    "\n",
    "y_pred = y_pred.numpy()\n",
    "y_true = y_true.numpy()\n",
    "\n",
    "y_test_pred = (y_pred > 0.5).astype(int)\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, y_pred)\n",
    "\n",
    "print(test_metrics)\n",
    "\n",
    "y_pred = y_pred.flatten()\n",
    "y_test_pred = y_test_pred.flatten()\n",
    "\n",
    "test_df_group_NN = categorize_predictions(X_test, y_test, y_test_pred, y_pred)\n",
    "test_df_group_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ha_tp_routes = test_df_group_HA[test_df_group_HA['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "nn_tp_routes = test_df_group_NN[test_df_group_NN['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "\n",
    "# Convert lists to sets of tuples for comparison\n",
    "ha_tp_routes_set = set(tuple(route) for route in ha_tp_routes)\n",
    "nn_tp_routes_set = set(tuple(route) for route in nn_tp_routes)\n",
    "\n",
    "# Find non-overlapping routes\n",
    "ha_only_routes = ha_tp_routes_set - nn_tp_routes_set\n",
    "nn_only_routes = nn_tp_routes_set - ha_tp_routes_set\n",
    "\n",
    "# Convert back to lists for display\n",
    "ha_only_routes = [list(route) for route in ha_only_routes]\n",
    "nn_only_routes = [list(route) for route in nn_only_routes]\n",
    "\n",
    "print(\"Routes unique to HA model:\", len(ha_only_routes))\n",
    "print(\"Sample of HA-only routes:\", ha_only_routes[:5])\n",
    "\n",
    "print(\"\\nRoutes unique to RF model:\", len(nn_only_routes))\n",
    "print(\"Sample of RF-only routes:\", nn_only_routes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# unique_days = final_routes['day_of_week'].unique()\n",
    "# day_of_week_encoded = pd.get_dummies(final_routes['day_of_week'], prefix='day_of_week')\n",
    "# final_routes = pd.concat([final_routes, day_of_week_encoded], axis=1)\n",
    "# final_routes\n",
    "print(len(y_pred), len(y_pred[y_pred>0.5]))\n",
    "print(len(y_test), len(y_test[y_test>0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def padding_(routes, route_len):\n",
    "    features = np.zeros((len(routes), route_len),dtype=np.float16)\n",
    "    for ii, route in enumerate(routes):\n",
    "        if len(route) != 0:\n",
    "            features[ii, -len(route):] = np.array(route)[:route_len]\n",
    "    return features\n",
    "\n",
    "X = final_routes_split.drop(columns = ['driver_id', 'len', 'driver_id_sorted','day_of_week_encoded'])\n",
    "max_route_length = max(len(item) for item in final_routes_split['routes'])\n",
    "y = np.array(final_routes_split['label'])\n",
    "# X = np.concatenate([padding_(X['routes'], max_route_length),padding_(X['distance_route'], max_route_length), X.to_numpy()[:,2:]], axis=1)\n",
    "# X = np.concatenate([padding_(X['routes'], max_route_length),padding_(X['distance_route'], max_route_length), padding_(X['experience_feature'], max_route_length), padding_(X['len_feature'], max_route_length), padding_(X['driver_id_feature'], max_route_length)], axis=1)\n",
    "# X = X.astype(np.float16)\n",
    "# X = X.astype(int) #for boolean values, to converst from string to int\n",
    "# final_routes\n",
    "final_routes_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Driver id and location id counting and overwritten with transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drivers_dic = {}\n",
    "k = 1\n",
    "for driver in final_routes_split['driver_id_sorted']:\n",
    "    if driver not in drivers_dic:\n",
    "        drivers_dic[driver] = k\n",
    "        k += 1\n",
    "print('Total number of drivers', len(drivers_dic))\n",
    "total_drivers = len(drivers_dic)\n",
    "encoding_drivers = []\n",
    "for driver in final_routes_split['driver_id_sorted']:\n",
    "    encoding_drivers.append(drivers_dic[driver])\n",
    "#\n",
    "final_routes_split['driver_id_sorted'] = encoding_drivers\n",
    "\n",
    "locations_dic = {}\n",
    "location_count = {}\n",
    "k = 1\n",
    "for row in final_routes_split['routes']:\n",
    "   for location in row:\n",
    "       if location not in locations_dic:\n",
    "           locations_dic[location] = k\n",
    "           k += 1\n",
    "k = 1\n",
    "print(len(locations_dic))\n",
    "\n",
    "for row in final_routes_split['routes']:\n",
    "   for location in row:\n",
    "       if location not in location_count:\n",
    "            location_count[location] = 1\n",
    "       else:\n",
    "            location_count[location] += 1\n",
    "encoding_routes = []\n",
    "for row in final_routes_split['routes']:\n",
    "    encoding_route = []\n",
    "    for location in row:\n",
    "        encoding_route.append(locations_dic[location])\n",
    "    encoding_routes.append(encoding_route)\n",
    "final_routes_split['routes'] = encoding_routes\n",
    "\n",
    "final_routes_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## List of features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "seed_value = 42\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Additional steps if using DataLoaders (to ensure reproducibility in data loading)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def reset_random():\n",
    "    g.manual_seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionRNN_bidirectional(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size, vocab_size_driv, vocab_size_len,hidden_dim,embedding_dim,embedding_dim_driv, output_dim,additional_feature_count,drop_prob=0.5):\n",
    "        super(PredictionRNN,self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab_size_driv = vocab_size_driv\n",
    "        self.vocab_size_len = vocab_size_len\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_driv = nn.Embedding(vocab_size_driv, embedding_dim_driv)\n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "        # embedding_dim_driv+2\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "\n",
    "\n",
    "        # dropout layer\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.no_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "\n",
    "        # The output of the BiLSTM will have twice the hidden size due to bidirectionality\n",
    "        self.lstm_output_size = self.hidden_dim * 2\n",
    "\n",
    "\n",
    "        # dropout layer\n",
    "        # self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        # self.fc_static_1 = nn.Linear(embedding_dim_driv+embedding_dim_len+9, 16)\n",
    "        self.fc_static_1 = nn.Linear(embedding_dim_driv+9, 128)\n",
    "        # self.fc_static_2 = nn.Linear(128, 128)\n",
    "        # # self.fc = nn.Linear(36, output_dim)\n",
    "        # # self.fc = nn.Linear(1316, output_dim)\n",
    "        self.fc = nn.Linear(128+self.lstm_output_size,128)\n",
    "        # # self.fc = nn.Linear(128,128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x, is_training=True):\n",
    "        batch_size = len(x['routes'])\n",
    "        route_ids = x['routes'].int()\n",
    "\n",
    "        embeds = self.embedding(route_ids)  # shape: B x S x Feature   since batch = True\n",
    "\n",
    "        # get driver ids example\n",
    "        driver_ids = x['driver_id_sorted'].int()\n",
    "        experience = x['last_two_weeks_count'].int()\n",
    "        len_feature = x['len'].int()\n",
    "        # distance = x['distance_route'].int()\n",
    "        day_of_week_feature = x['day_of_week_encoded_ext'].int()\n",
    "        country_flag = x['country_flag'].int()\n",
    "        location_is_depot = x['location_is_depot'].int()\n",
    "        location_type_id = x['location_type_id'].int()\n",
    "\n",
    "        embedding_driv = self.embedding_driv(driver_ids)\n",
    "        # ,distance.view(batch_size, max_route_length, 1)\n",
    "        # experience.view(batch_size, max_route_length, 1)\n",
    "\n",
    "        # all_embeds = torch.concatenate((embeds, distance.view(batch_size, max_route_length, 1), location_is_depot.view(batch_size, max_route_length, 1), location_type_id.view(batch_size, max_route_length, 1)), dim=2)\n",
    "        all_embeds = embeds\n",
    "\n",
    "        # all_static = torch.concatenate((embedding_driv, embedding_len, day_of_week_feature, country_flag.view(batch_size, 1),experience.view(batch_size, 1)), dim=1)\n",
    "        all_static = torch.concatenate((embedding_driv, country_flag.view(batch_size, 1),len_feature.view(batch_size, 1), day_of_week_feature), dim=1)\n",
    "        # all_static = torch.concatenate((embedding_driv, day_of_week_feature), dim=1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(all_embeds)\n",
    "        # lstm_out = lstm_out.contiguous().view(batch_size, self.lstm_output_size, self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "\n",
    "        out_static = self.relu(self.fc_static_1(all_static))\n",
    "        # out_static = self.dropout(self.fc_static_2(out_static))\n",
    "        # out_static = out_static.unsqueeze(1)\n",
    "        static_expanded = out_static.unsqueeze(1).expand(-1, lstm_out.size(1), -1)\n",
    "\n",
    "        combined = self.fc(torch.cat((out, static_expanded), dim=2))\n",
    "        # out = self.fc(torch.concatenate((out, out_static), dim=1))\n",
    "        # out_static = out_static.squeeze(1).unsqueeze(1).repeat(1, 36, 1)  # New shape: [2048, 36, 64]\n",
    "        # out = self.fc(torch.cat((out, out_static), dim=2))\n",
    "        x = self.relu(combined)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        # out = self.dropout(x)\n",
    "        out = self.layer3(x)\n",
    "        # print(out.shape)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # print(sig_out.shape)\n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionRNN(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size, vocab_size_driv, vocab_size_len,hidden_dim,embedding_dim,embedding_dim_driv, output_dim,additional_feature_count,drop_prob=0.5):\n",
    "        super(PredictionRNN,self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab_size_driv = vocab_size_driv\n",
    "        self.vocab_size_len = vocab_size_len\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_driv = nn.Embedding(vocab_size_driv, embedding_dim_driv)\n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim+1,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        # self.fc_static_1 = nn.Linear(embedding_dim_driv+embedding_dim_len+9, 16)\n",
    "        self.fc_static_1 = nn.Linear(embedding_dim_driv+9, 128)\n",
    "        # self.fc_static_2 = nn.Linear(128, 128)\n",
    "        # # self.fc = nn.Linear(36, output_dim)\n",
    "        # # self.fc = nn.Linear(1316, output_dim)\n",
    "        self.fc = nn.Linear(128,128) #128\n",
    "        # # self.fc = nn.Linear(128,128)\n",
    "        # self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x, is_training=True):\n",
    "        batch_size = len(x['routes'])\n",
    "        route_ids = x['routes'].int()\n",
    "\n",
    "        embeds = self.embedding(route_ids)  # shape: B x S x Feature   since batch = True\n",
    "\n",
    "        # get driver ids example\n",
    "        driver_ids = x['driver_id_sorted'].int()\n",
    "        experience = x['last_two_weeks_count'].int()\n",
    "        len_feature = x['len'].int()\n",
    "        distance = x['distance_route'].int()\n",
    "        day_of_week_feature = x['day_of_week_encoded_ext'].int()\n",
    "        country_flag = x['country_flag'].int()\n",
    "        location_is_depot = x['location_is_depot'].int()\n",
    "        location_type_id = x['location_type_id'].int()\n",
    "\n",
    "        embedding_driv = self.embedding_driv(driver_ids)\n",
    "\n",
    "\n",
    "        all_embeds = torch.concatenate((embeds, distance.view(batch_size, max_route_length, 1)), dim=2)\n",
    "\n",
    "        # all_embeds = torch.concatenate((embeds, distance.view(batch_size, max_route_length, 1), location_is_depot.view(batch_size, max_route_length, 1), location_type_id.view(batch_size, max_route_length, 1)), dim=2)\n",
    "        # all_embeds = embeds\n",
    "\n",
    "        # all_static = torch.concatenate((embedding_driv, embedding_len, day_of_week_feature, country_flag.view(batch_size, 1),experience.view(batch_size, 1)), dim=1)\n",
    "        all_static = torch.concatenate((embedding_driv, day_of_week_feature, country_flag.view(batch_size, 1), len_feature.view(batch_size, 1)), dim=1)\n",
    "        # all_static = torch.concatenate((embedding_driv, day_of_week_feature), dim=1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(all_embeds)\n",
    "        lstm_out = lstm_out.contiguous().view(batch_size, max_route_length, self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "\n",
    "        out_static = self.relu(self.fc_static_1(all_static))\n",
    "        out = self.fc(out_static)\n",
    "        x = self.relu(out)\n",
    "        # x = self.relu(self.layer2(out))\n",
    "        out = self.layer3(x)\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # print(sig_out.shape)\n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionAllFeaturesCNN(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, vocab_size_driv, embedding_dim, embedding_dim_driv, output_dim, drop_prob=0.5):\n",
    "        super(PredictionAllFeaturesCNN, self).__init__()\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab_size_driv = vocab_size_driv\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_driv = nn.Embedding(vocab_size_driv, embedding_dim_driv)\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "        # embedding_dim_driv+2\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "\n",
    "\n",
    "        # dropout layer\n",
    "        # self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "        #                    num_layers=no_layers, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        # self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        # self.fc_static_1 = nn.Linear(embedding_dim_driv+embedding_dim_len+9, 16)\n",
    "        self.fc_static_1 = nn.Linear(embedding_dim_driv+9, 128)\n",
    "        # self.fc_static_2 = nn.Linear(128, 128)\n",
    "        # # self.fc = nn.Linear(36, output_dim)\n",
    "        # # self.fc = nn.Linear(1316, output_dim)\n",
    "        self.fc = nn.Linear(128+64,64)\n",
    "        # # self.fc = nn.Linear(128,128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        batch_size = len(x['routes'])\n",
    "        route_ids = x['routes'].int()\n",
    "\n",
    "        embeds = self.embedding(route_ids)  # shape: B x S x Feature   since batch = True\n",
    "\n",
    "        # get driver ids example\n",
    "        driver_ids = x['driver_id_sorted'].int()\n",
    "        experience = x['last_two_weeks_count'].int()\n",
    "        len_feature = x['len'].int()\n",
    "        # distance = x['distance_route'].int()\n",
    "        day_of_week_feature = x['day_of_week_encoded_ext'].int()\n",
    "        country_flag = x['country_flag'].int()\n",
    "        location_is_depot = x['location_is_depot'].int()\n",
    "        location_type_id = x['location_type_id'].int()\n",
    "\n",
    "        embedding_driv = self.embedding_driv(driver_ids)\n",
    "        # ,distance.view(batch_size, max_route_length, 1)\n",
    "        # experience.view(batch_size, max_route_length, 1)\n",
    "\n",
    "        # all_embeds = torch.concatenate((embeds, distance.view(batch_size, max_route_length, 1), location_is_depot.view(batch_size, max_route_length, 1), location_type_id.view(batch_size, max_route_length, 1)), dim=2)\n",
    "        all_embeds = embeds\n",
    "\n",
    "        # all_static = torch.concatenate((embedding_driv, embedding_len, day_of_week_feature, country_flag.view(batch_size, 1),experience.view(batch_size, 1)), dim=1)\n",
    "        all_static = torch.concatenate((embedding_driv, country_flag.view(batch_size, 1), day_of_week_feature, len_feature.view(batch_size, 1)), dim=1)\n",
    "        # all_static = torch.concatenate((embedding_driv, day_of_week_feature), dim=1)\n",
    "\n",
    "\n",
    "        cnn_input = embeds.permute(0, 2, 1)  # Reshape for CNN: B x Feature x S\n",
    "        cnn_out = self.conv1(cnn_input)\n",
    "        cnn_out = self.relu(cnn_out)\n",
    "        cnn_out = self.pool(cnn_out)\n",
    "        # cnn_out = cnn_out.permute(0, 2, 1)\n",
    "        cnn_out = torch.mean(cnn_out, dim=2)\n",
    "        cnn_out = self.dropout(cnn_out)\n",
    "\n",
    "        # lstm_out, _ = self.lstm(cnn_out)\n",
    "        # # lstm_out = lstm_out.contiguous().view(batch_size, max_route_length, self.hidden_dim)\n",
    "        # lstm_out = lstm_out.contiguous().view(batch_size, -1, self.hidden_dim)\n",
    "        # out = self.dropout(lstm_out)\n",
    "\n",
    "        out_static = self.relu(self.fc_static_1(all_static))\n",
    "        # out_static = self.dropout(self.fc_static_2(out_static))\n",
    "        # out_static = out_static.unsqueeze(1)\n",
    "\n",
    "        combined = self.fc(torch.cat((cnn_out, out_static), dim=1))\n",
    "        # out = self.fc(torch.concatenate((out, out_static), dim=1))\n",
    "        # out_static = out_static.squeeze(1).unsqueeze(1).repeat(1, 36, 1)  # New shape: [2048, 36, 64]\n",
    "        # out = self.fc(torch.cat((out, out_static), dim=2))\n",
    "        x = self.relu(combined)\n",
    "        # x = self.relu(self.layer2(out))\n",
    "        # out = self.dropout(x)\n",
    "        out = self.layer3(x)\n",
    "        # print(out.shape)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # print(sig_out.shape)\n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PredictionAllFeaturesGRU(nn.Module):\n",
    "    def __init__(self, no_layers, vocab_size, vocab_size_driv, embedding_dim, embedding_dim_driv, hidden_dim, output_dim, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.no_layers = no_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab_size_driv = vocab_size_driv\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_driv = nn.Embedding(vocab_size_driv, embedding_dim_driv)\n",
    "\n",
    "        # GRU layer for route features\n",
    "        self.gru = nn.GRU(input_size=embedding_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=no_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=drop_prob if no_layers > 1 else 0)\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc_static_1 = nn.Linear(embedding_dim_driv+8, 128)\n",
    "        self.fc = nn.Linear(128+hidden_dim, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = len(x['routes'])\n",
    "        route_ids = x['routes'].int()\n",
    "\n",
    "        embeds = self.embedding(route_ids)  # shape: B x S x Feature\n",
    "\n",
    "        # Static features\n",
    "        driver_ids = x['driver_id_sorted'].int()\n",
    "        experience = x['last_two_weeks_count'].int()\n",
    "        len_feature = x['len'].int()\n",
    "        day_of_week_feature = x['day_of_week_encoded_ext'].int()\n",
    "        country_flag = x['country_flag'].int()\n",
    "        location_is_depot = x['location_is_depot'].int()\n",
    "        location_type_id = x['location_type_id'].int()\n",
    "\n",
    "        embedding_driv = self.embedding_driv(driver_ids)\n",
    "\n",
    "        all_static = torch.cat((embedding_driv, country_flag.view(batch_size, 1),\n",
    "                                len_feature.view(batch_size, 1), day_of_week_feature), dim=1)\n",
    "\n",
    "        # Process route features with GRU\n",
    "        gru_out, _ = self.gru(embeds)\n",
    "        gru_out = gru_out[:, -1, :]  # Take the last output of the sequence\n",
    "        gru_out = self.dropout(gru_out)\n",
    "\n",
    "        out_static = self.relu(self.fc_static_1(all_static))\n",
    "\n",
    "        combined = self.fc(torch.cat((gru_out, out_static), dim=1))\n",
    "        x = self.relu(combined)\n",
    "        out = self.layer3(x)\n",
    "\n",
    "        sig_out = self.sig(out)\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]  # get last batch of labels\n",
    "\n",
    "        return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class RunningNorm:\n",
    "    def __init__(self, dim=0):\n",
    "        self.dim = dim\n",
    "        self.n = 0\n",
    "        self.mean = 0\n",
    "        self.var = 0\n",
    "\n",
    "    def update(self, x):\n",
    "        self.n += 1\n",
    "        if self.n == 1:\n",
    "            self.mean = x\n",
    "            self.var = torch.zeros_like(x)\n",
    "        else:\n",
    "            new_mean = self.mean + (x - self.mean) / self.n\n",
    "            self.var = (self.var * (self.n - 1) + (x - self.mean) * (x - new_mean)) / self.n\n",
    "            self.mean = new_mean\n",
    "\n",
    "    def normalize(self, x):\n",
    "        if self.n == 0:\n",
    "            return x\n",
    "        return (x - self.mean) / (torch.sqrt(self.var) + 1e-8)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=35):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape should be (batch_size, sequence_length, d_model)\n",
    "        sequence_length = x.size(1)\n",
    "        x = x + self.pe[:, :sequence_length, :]\n",
    "        return x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "# \"Encoder-Only\" Style Transformer\n",
    "class NanoTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a simplified Transformer model for sequence classification.\n",
    "    It uses an embedding layer for tokens, sinusoidal positional embeddings,\n",
    "    a single Transformer block, and a final linear layer for prediction.\n",
    "\n",
    "    Args:\n",
    "      num_emb: The number of unique tokens in the vocabulary.\n",
    "      output_size: The size of the output layer (number of classes).\n",
    "      hidden_size: The dimension of the hidden layer in the Transformer block (default: 128).\n",
    "      num_heads: The number of heads in the multi-head attention layer (default: 4).\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim, vocab_size, embedding_dim_driv, vocab_size_driv, hidden_size=64, num_heads=4):\n",
    "        super(NanoTransformer, self).__init__()\n",
    "\n",
    "        # Create an embedding for each token\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding_driv = nn.Embedding(vocab_size_driv, embedding_dim_driv)\n",
    "        self.embedding.weight.data = 0.001 * self.embedding.weight.data\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim_driv = embedding_dim_driv\n",
    "        self.vocab_size_driv = vocab_size_driv\n",
    "\n",
    "        self.pos_emb = SinusoidalPosEmb(hidden_size)\n",
    "\n",
    "        self.multihead_attn1 = nn.MultiheadAttention(hidden_size, num_heads=num_heads, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.fc_static_1 = nn.Linear(embedding_dim_driv+9, 128)\n",
    "        self.layer3 = nn.Linear(128, 1)\n",
    "        self.fc = nn.Linear(hidden_size+128, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, is_training=True):\n",
    "        bs = len(x['routes'])\n",
    "        l = len(x['routes'][0])\n",
    "        route_ids = x['routes'].int()\n",
    "        input_embs = self.embedding(route_ids)  # shape: B x S x Feature   since batch = True\n",
    "\n",
    "        driver_ids = x['driver_id_sorted'].int()\n",
    "        experience = x['last_two_weeks_count'].float()\n",
    "        len_feature = x['len'].float()\n",
    "        day_of_week_feature = x['day_of_week_encoded_ext'].int()\n",
    "        country_flag = x['country_flag'].int()\n",
    "        location_is_depot = x['location_is_depot'].int()\n",
    "        location_type_id = x['location_type_id'].int()\n",
    "\n",
    "        embedding_driv = self.embedding_driv(driver_ids)\n",
    "\n",
    "        all_static = torch.cat((embedding_driv, country_flag.view(bs, 1),\n",
    "                                len_feature.view(bs, 1), day_of_week_feature), dim=1)\n",
    "\n",
    "\n",
    "        seq_indx = torch.arange(l)\n",
    "        pos_emb = self.pos_emb(seq_indx).reshape(1, l, -1).expand(bs, l, -1)\n",
    "        embs = input_embs + pos_emb\n",
    "        output1, attn_map1 = self.multihead_attn1(embs, embs, embs)\n",
    "        output = self.layer_norm(embs + output1)\n",
    "\n",
    "        out_static = self.relu(self.fc_static_1(all_static))\n",
    "        out_static = out_static.unsqueeze(1).expand(-1, l, -1)\n",
    "\n",
    "        out = self.fc(torch.cat((output, out_static), dim=2))\n",
    "        out = self.layer3(out)\n",
    "        sig_out = self.sig(out).squeeze(-1)\n",
    "        final_out = torch.mean(sig_out, dim=1)\n",
    "        # seq_indx = torch.arange(l)\n",
    "        # pos_emb = self.pos_emb(seq_indx).reshape(1, l, -1).expand(bs, l, -1)\n",
    "        # embs = input_embs + pos_emb\n",
    "        # output, attn_map = self.multihead_attn(embs, embs, embs)\n",
    "        #\n",
    "        # out_static = self.bn1(self.relu(self.fc_static_1(all_static)))\n",
    "        #\n",
    "        # out_static = out_static.squeeze(1).unsqueeze(1).repeat(1, 36, 1)  # New shape: [2048, 36, 64]\n",
    "        # out = self.fc(torch.cat((output, out_static), dim=2))\n",
    "\n",
    "        # print(out.shape)\n",
    "        # out = self.layer3(out)\n",
    "        # sig_out = self.sig(out)\n",
    "        # print(sig_out.shape)\n",
    "        # sig_out = sig_out.view(bs, -1)\n",
    "        # print(sig_out.shape)\n",
    "        # sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        # print(sig_out.shape)\n",
    "        # raise 'ere'\n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    no_layers = 2\n",
    "    vocab_size = 10547 #extra 1 for padding\n",
    "    vocab_size_driv = 315\n",
    "    vocab_size_len = 37 #extra 1 for padding\n",
    "    embedding_dim = 64 #was 64\n",
    "    embedding_dim_driv = 32 #was 64\n",
    "    # embedding_dim_len = 2 #was 64\n",
    "    output_dim = 1\n",
    "    hidden_dim = 64 #was 64\n",
    "\n",
    "    model = PredictionAllFeaturesCNN(no_layers, vocab_size, vocab_size_driv, embedding_dim, embedding_dim_driv, output_dim, drop_prob=0.5)\n",
    "    # model = PredictionRNN(no_layers,vocab_size, vocab_size_driv, vocab_size_len, hidden_dim,embedding_dim, embedding_dim_driv, output_dim,len(drivers_dic),drop_prob=0.5)\n",
    "    # model = NanoTransformer(embedding_dim, vocab_size, embedding_dim_driv, vocab_size_driv)\n",
    "    model.train()\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# function to predict accuracy\n",
    "# def acc(pred,label):\n",
    "#     pred = torch.round(pred.squeeze())\n",
    "#     return torch.sum(pred == label.squeeze()).item()\n",
    "\n",
    "def rmse(pred, label):\n",
    "    return torch.sqrt(torch.mean((pred.squeeze() - label.squeeze())**2))\n",
    "\n",
    "# def get_precision(pred, label):\n",
    "#     pred = torch.round(pred.squeeze())\n",
    "#     true_positive = torch.sum((pred == 1) & (label.squeeze() == 1)).item()\n",
    "#     false_positive = torch.sum((pred == 1) & (label.squeeze() == 0)).item()\n",
    "#\n",
    "#     if true_positive + false_positive == 0:\n",
    "#         return 0.0, true_positive, false_positive  # Handle the case where there are no predicted positives\n",
    "#\n",
    "#     precision_value = true_positive / (true_positive + false_positive)\n",
    "#     return precision_value, true_positive, false_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RUN_NAME = 'first_run_5'\n",
    "def train_model(data, model, epochs = 20):\n",
    "    train_loader, valid_loader = data\n",
    "    lr=0.001\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    clip = 5\n",
    "    valid_loss_min = np.Inf\n",
    "    # train for some number of epochs\n",
    "    epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "    epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "    epoch_tr_precision,epoch_vl_precision = [],[]\n",
    "    # wandb.init(project='Route_classification', name=f'{run_name}')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        train_rmse = 0.0\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            # print(labels)\n",
    "\n",
    "            model.zero_grad()\n",
    "            # print(inputs.shape, h[0].shape, h[1].shape)\n",
    "            output = model(inputs)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            # print(output, labels)\n",
    "            # print(output.shape, labels.shape)\n",
    "            loss = criterion(output.view(-1), labels.float())\n",
    "            loss.backward()\n",
    "            train_losses.append(loss.item())\n",
    "            #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "        val_losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # Disable gradient computation for validation\n",
    "            for inputs, labels in valid_loader:\n",
    "                output = model(inputs, is_training=False)  # Set is_training to False for validation\n",
    "                val_loss = criterion(output.view(-1), labels.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "        epoch_train_loss = np.mean(train_losses)\n",
    "        epoch_val_loss = np.mean(val_losses)\n",
    "\n",
    "        epoch_tr_loss.append(epoch_train_loss)\n",
    "        epoch_vl_loss.append(epoch_val_loss)\n",
    "        print(f'Epoch {epoch+1}')\n",
    "        print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "\n",
    "        if epoch_val_loss <= valid_loss_min:\n",
    "            torch.save(model.state_dict(), f'{RUN_NAME}.pt')\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "            valid_loss_min = epoch_val_loss\n",
    "        print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, log_loss, brier_score_loss, confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_stats(model, data):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y = []\n",
    "    all_routes = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in data:\n",
    "            y.extend(labels)\n",
    "            results = model(inputs, is_training=False).detach()  # Set is_training to False\n",
    "            y_pred.extend(results)\n",
    "            all_routes.extend(inputs['routes'].cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y)\n",
    "    y_pred_proba = np.array(y_pred)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(np.float32)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    average_precision = average_precision_score(y_true, y_pred)\n",
    "    quadratic_loss = log_loss(y_true, y_pred_proba)\n",
    "    brier_score = brier_score_loss(y_true, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": average_precision,\n",
    "        \"quadratic_loss\": quadratic_loss,\n",
    "        \"brier_score\": brier_score,\n",
    "        \"true_positive\": tp,\n",
    "        \"false_positive\": fp,\n",
    "        \"true_negative\": tn,\n",
    "        \"false_negative\": fn\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_stats(model, data):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y = []\n",
    "    all_inputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data:\n",
    "            y.extend(labels.cpu().numpy())\n",
    "            results = model(inputs, is_training=False).detach()\n",
    "            y_pred.extend(results.cpu().numpy())\n",
    "            all_inputs.append({k: v.cpu().numpy() for k, v in inputs.items()})\n",
    "\n",
    "    y_true = np.array(y)\n",
    "    y_pred_proba = np.array(y_pred)\n",
    "    y_pred_binary = (y_pred_proba > 0.5).astype(np.float32)\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_true, y_pred_binary)\n",
    "    precision = precision_score(y_true, y_pred_binary)\n",
    "    recall = recall_score(y_true, y_pred_binary)\n",
    "    f1 = f1_score(y_true, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    average_precision = average_precision_score(y_true, y_pred_proba)\n",
    "    quadratic_loss = log_loss(y_true, y_pred_proba)\n",
    "    brier_score = brier_score_loss(y_true, y_pred_proba)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
    "\n",
    "    # Combine all inputs into a single dictionary\n",
    "    combined_inputs = {k: np.concatenate([d[k] for d in all_inputs]) for k in all_inputs[0].keys()}\n",
    "\n",
    "    return {\n",
    "        \"metrics\": {\n",
    "            \"acc\": acc,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"average_precision\": average_precision,\n",
    "            \"quadratic_loss\": quadratic_loss,\n",
    "            \"brier_score\": brier_score,\n",
    "            \"true_positive\": tp,\n",
    "            \"false_positive\": fp,\n",
    "            \"true_negative\": tn,\n",
    "            \"false_negative\": fn\n",
    "        },\n",
    "        \"predictions\": {\n",
    "            \"y_true\": y_true,\n",
    "            \"y_pred_proba\": y_pred_proba,\n",
    "            \"y_pred_binary\": y_pred_binary,\n",
    "            \"inputs\": combined_inputs\n",
    "        }\n",
    "    }\n",
    "\n",
    "def categorize_predictions(df, stats):\n",
    "    y_true = stats['predictions']['y_true']\n",
    "    y_pred_binary = stats['predictions']['y_pred_binary']\n",
    "    y_pred_proba = stats['predictions']['y_pred_proba']\n",
    "\n",
    "    df = df.copy()\n",
    "    df['prediction_category'] = 'Unknown'\n",
    "    df.loc[(y_true == 1) & (y_pred_binary == 1), 'prediction_category'] = 'True Positive'\n",
    "    df.loc[(y_true == 0) & (y_pred_binary == 1), 'prediction_category'] = 'False Positive'\n",
    "    df.loc[(y_true == 1) & (y_pred_binary == 0), 'prediction_category'] = 'False Negative'\n",
    "    df.loc[(y_true == 0) & (y_pred_binary == 0), 'prediction_category'] = 'True Negative'\n",
    "    df['predictive_probability'] = y_pred_proba\n",
    "\n",
    "    # Add other features from the inputs if needed\n",
    "    for feature, values in stats['predictions']['inputs'].items():\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_df) = 13823, len(val_df) = 2188, len(test_df) = 1656\n",
      "PredictionAllFeaturesCNN(\n",
      "  (embedding): Embedding(10547, 64)\n",
      "  (embedding_driv): Embedding(315, 32)\n",
      "  (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc_static_1): Linear(in_features=41, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=192, out_features=64, bias=True)\n",
      "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "Epoch 1\n",
      "train_loss : 0.23393566961641665 val_loss : 0.24727883636951448\n",
      "Validation loss decreased (inf --> 0.247279).  Saving model ...\n",
      "==================================================\n",
      "Epoch 2\n",
      "train_loss : 0.2386853579017851 val_loss : 0.2239043891429901\n",
      "Validation loss decreased (0.247279 --> 0.223904).  Saving model ...\n",
      "==================================================\n",
      "Epoch 3\n",
      "train_loss : 0.21808989870327491 val_loss : 0.21747974753379823\n",
      "Validation loss decreased (0.223904 --> 0.217480).  Saving model ...\n",
      "==================================================\n",
      "Epoch 4\n",
      "train_loss : 0.20896213087770674 val_loss : 0.2090667724609375\n",
      "Validation loss decreased (0.217480 --> 0.209067).  Saving model ...\n",
      "==================================================\n",
      "Epoch 5\n",
      "train_loss : 0.19726335064128594 val_loss : 0.20351193249225616\n",
      "Validation loss decreased (0.209067 --> 0.203512).  Saving model ...\n",
      "==================================================\n",
      "Epoch 6\n",
      "train_loss : 0.1875059199002054 val_loss : 0.19637228846549987\n",
      "Validation loss decreased (0.203512 --> 0.196372).  Saving model ...\n",
      "==================================================\n",
      "Epoch 7\n",
      "train_loss : 0.17841262342753234 val_loss : 0.19201841652393342\n",
      "Validation loss decreased (0.196372 --> 0.192018).  Saving model ...\n",
      "==================================================\n",
      "Epoch 8\n",
      "train_loss : 0.16998951385418573 val_loss : 0.1878793865442276\n",
      "Validation loss decreased (0.192018 --> 0.187879).  Saving model ...\n",
      "==================================================\n",
      "Epoch 9\n",
      "train_loss : 0.16250289838623116 val_loss : 0.18474003970623015\n",
      "Validation loss decreased (0.187879 --> 0.184740).  Saving model ...\n",
      "==================================================\n",
      "Epoch 10\n",
      "train_loss : 0.15606619500451618 val_loss : 0.18291567265987396\n",
      "Validation loss decreased (0.184740 --> 0.182916).  Saving model ...\n",
      "==================================================\n",
      "Epoch 11\n",
      "train_loss : 0.15060724511190696 val_loss : 0.18154819011688234\n",
      "Validation loss decreased (0.182916 --> 0.181548).  Saving model ...\n",
      "==================================================\n",
      "Epoch 12\n",
      "train_loss : 0.14632261047760645 val_loss : 0.18141047656536102\n",
      "Validation loss decreased (0.181548 --> 0.181410).  Saving model ...\n",
      "==================================================\n",
      "Epoch 13\n",
      "train_loss : 0.14228373959108634 val_loss : 0.1808433473110199\n",
      "Validation loss decreased (0.181410 --> 0.180843).  Saving model ...\n",
      "==================================================\n",
      "Epoch 14\n",
      "train_loss : 0.13872022374912543 val_loss : 0.18129801154136657\n",
      "==================================================\n",
      "Epoch 15\n",
      "train_loss : 0.13666980465253195 val_loss : 0.18143586218357086\n",
      "==================================================\n",
      "Epoch 16\n",
      "train_loss : 0.13355321492309924 val_loss : 0.1843635082244873\n",
      "==================================================\n",
      "Epoch 17\n",
      "train_loss : 0.13174067713596202 val_loss : 0.1838030844926834\n",
      "==================================================\n",
      "Epoch 18\n",
      "train_loss : 0.13268091281255087 val_loss : 0.185374116897583\n",
      "==================================================\n",
      "Epoch 19\n",
      "train_loss : 0.1302646020496333 val_loss : 0.18554314374923705\n",
      "==================================================\n",
      "Epoch 20\n",
      "train_loss : 0.12934277951717377 val_loss : 0.1827765703201294\n",
      "==================================================\n",
      "Epoch 21\n",
      "train_loss : 0.12537169456481934 val_loss : 0.18774695098400115\n",
      "==================================================\n",
      "Epoch 22\n",
      "train_loss : 0.12194790773921543 val_loss : 0.19667756855487822\n",
      "==================================================\n",
      "Epoch 23\n",
      "train_loss : 0.12463454791793117 val_loss : 0.20688232481479646\n",
      "==================================================\n",
      "Epoch 24\n",
      "train_loss : 0.1277806187669436 val_loss : 0.22059226036071777\n",
      "==================================================\n",
      "Epoch 25\n",
      "train_loss : 0.13483131428559622 val_loss : 0.19481210112571717\n",
      "==================================================\n",
      "Epoch 26\n",
      "train_loss : 0.13558424567734753 val_loss : 0.19181489050388337\n",
      "==================================================\n",
      "Epoch 27\n",
      "train_loss : 0.1320658777323034 val_loss : 0.18153786659240723\n",
      "==================================================\n",
      "Epoch 28\n",
      "train_loss : 0.1157597369617886 val_loss : 0.1874466508626938\n",
      "==================================================\n",
      "Epoch 29\n",
      "train_loss : 0.111513149821096 val_loss : 0.19090724289417266\n",
      "==================================================\n",
      "Epoch 30\n",
      "train_loss : 0.10971327940071071 val_loss : 0.19143144488334657\n",
      "==================================================\n",
      "Epoch 31\n",
      "train_loss : 0.10646106716659334 val_loss : 0.1931874692440033\n",
      "==================================================\n",
      "Epoch 32\n",
      "train_loss : 0.10514532208994583 val_loss : 0.1974359929561615\n",
      "==================================================\n",
      "Epoch 33\n",
      "train_loss : 0.10407549529163926 val_loss : 0.19759514033794404\n",
      "==================================================\n",
      "Epoch 34\n",
      "train_loss : 0.10141157924577042 val_loss : 0.19876560866832732\n",
      "==================================================\n",
      "Epoch 35\n",
      "train_loss : 0.10053207987436542 val_loss : 0.1997927963733673\n",
      "==================================================\n",
      "Epoch 36\n",
      "train_loss : 0.10074424274541714 val_loss : 0.19811736643314362\n",
      "==================================================\n",
      "Epoch 37\n",
      "train_loss : 0.10082664837439854 val_loss : 0.20175107419490815\n",
      "==================================================\n",
      "Epoch 38\n",
      "train_loss : 0.10165318074049773 val_loss : 0.2130078136920929\n",
      "==================================================\n",
      "Epoch 39\n",
      "train_loss : 0.10587342483577905 val_loss : 0.20646910667419432\n",
      "==================================================\n",
      "Epoch 40\n",
      "train_loss : 0.10536294278723222 val_loss : 0.20780619978904724\n",
      "==================================================\n",
      "PredictionAllFeaturesCNN(\n",
      "  (embedding): Embedding(10547, 64)\n",
      "  (embedding_driv): Embedding(315, 32)\n",
      "  (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc_static_1): Linear(in_features=41, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=192, out_features=64, bias=True)\n",
      "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sig): Sigmoid()\n",
      ")\n",
      "Metrics: {'acc': 0.7306763285024155, 'precision': 0.7411642411642412, 'recall': 0.7835164835164835, 'f1': 0.7617521367521367, 'roc_auc': 0.8079265238782665, 'average_precision': 0.8336324757966893, 'quadratic_loss': 0.542081372254347, 'brier_score': 0.1799140261601466, 'true_positive': 713, 'false_positive': 249, 'true_negative': 497, 'false_negative': 197}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "set_seed(42)\n",
    "\n",
    "FEATURE_COLUMNS = ['routes', 'driver_id_feature', 'driver_id_sorted','last_two_weeks_count', 'len', 'day_of_week_feature', 'day_of_week_encoded_ext', 'country_flag', 'location_is_depot', 'location_type_id', 'distance_route']\n",
    "\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for col in FEATURE_COLUMNS:\n",
    "            feature = self.df[col].iloc[idx]\n",
    "            if isinstance(feature, list):\n",
    "                feature = padding_([feature], max_route_length)[0]\n",
    "            item[col] = feature\n",
    "        item['label'] = self.df['label'].iloc[idx]\n",
    "        return item, item['label']\n",
    "\n",
    "def get_data_loaders(train_df, val_df, test_df):\n",
    "    # create Tensor datasets\n",
    "    train_data = DataFrameDataset(train_df)\n",
    "    val_data = DataFrameDataset(val_df)\n",
    "    test_data = DataFrameDataset(test_df)\n",
    "\n",
    "    # dataloaders\n",
    "    batch_size = 512\n",
    "\n",
    "    # make sure to SHUFFLE your data\n",
    "    train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size, num_workers=0, generator=g, worker_init_fn=seed_worker)\n",
    "    val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size, num_workers=0, generator=g, worker_init_fn=seed_worker)\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size,num_workers=0, generator=g, worker_init_fn=seed_worker)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_df = final_routes_split[final_routes_split['split'] == 'train'].drop('split', axis=1)\n",
    "val_df = final_routes_split[final_routes_split['split'] == 'val'].drop('split', axis=1)\n",
    "test_df = final_routes_split[final_routes_split['split'] == 'test'].drop('split', axis=1)\n",
    "\n",
    "print(f'len(train_df) = {len(train_df)}, len(val_df) = {len(val_df)}, len(test_df) = {len(test_df)}')\n",
    "\n",
    "train_loader, val_loader, test_loader = get_data_loaders(train_df, val_df, test_df)\n",
    "model = get_model()\n",
    "model.train()\n",
    "\n",
    "# Train the model\n",
    "train_model((train_loader, val_loader), model, epochs=40)\n",
    "\n",
    "# Load the best model\n",
    "model = get_model()\n",
    "model.load_state_dict(torch.load(f'{RUN_NAME}.pt'))\n",
    "\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_stats = get_stats(model, test_loader)\n",
    "\n",
    "print(\"Metrics:\", test_stats['metrics'])\n",
    "\n",
    "categorized_df = categorize_predictions(test_df, test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( categorized_df[categorized_df['prediction_category'] == 'False Negative']['routes'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 497\n",
      "Routes unique to HA model: 55 414\n",
      "Sample of HA-only routes: [[1022, 1452, 1342, 1844, 7583, 1022, 1407, 1396, 1386, 1022], [1, 4938, 4934, 570, 6461, 4940, 315, 907, 6196, 536], [912, 1010, 1012, 1012, 1017, 1019, 1020, 1016, 1016, 1011, 1014, 952, 912], [8594, 9413, 9412, 8759, 10173, 8805, 9960, 9961, 9416, 10185, 9454, 10178, 10178, 9417, 9438], [8594, 9465, 8663, 9373, 9373, 9422, 8699, 8699, 8652, 8661, 8708, 8707, 9377, 8667, 9225, 8594], [912, 4035, 4036, 4037, 4044, 4048, 4039, 4040, 4053, 4049], [1, 780, 1185, 69, 776, 8199, 73, 72, 7994, 74, 7993, 71, 7034, 783], [4108, 4108, 4108, 4108, 4108, 4144, 4143, 912, 4132, 912], [912, 1096, 3429, 3429, 1097, 1098, 5350, 1099, 3987, 1100, 1100, 5349, 1104], [912, 4542, 3537, 3538, 3539, 4543, 4363, 3706, 4544, 3542, 4545, 4364, 3543, 3544, 3545, 3545, 3546, 3540, 4367], [1, 341, 52, 46, 38, 35, 47, 37, 53, 349, 347, 36, 348, 348, 76, 64, 75, 75, 354, 1], [1022, 1332, 1467, 1022, 1338, 1522, 1369, 1475, 1566, 1426, 7604, 1474, 1499], [1, 1225, 1184, 1194, 780, 1201, 785, 1207, 1196, 1204, 45, 45, 1193, 1228, 1174, 1172, 1180, 783], [1884, 2697, 2570, 2454, 2454, 2181, 2039, 1916, 5054], [912, 3968, 3573, 3927, 3927, 3012, 947, 947, 3382, 3381, 918], [8594, 9913, 9753, 9756, 9756, 9890, 9915, 9916, 8594, 8940, 9917, 9946, 8975, 8976, 8977, 9795, 9919, 8974, 8974, 9966, 8594], [8594, 9840, 9743, 9841, 9842, 8925, 9844, 9844, 8937, 9992, 8979, 9978, 8969, 9179, 9186, 9404, 9006, 8594], [1884, 2062, 2352, 1994, 3282, 2114, 8549, 6582, 2059, 2522, 2291, 1932, 3327, 1906, 2000, 2734, 2013], [912, 3468, 3469, 3470, 3470, 3471, 3472, 3473, 3474, 3474], [912, 3469, 3468, 3468, 3470, 3471, 3472, 3473, 3475, 3474, 3476, 3477, 912, 912], [912, 4036, 4044, 4039, 4052, 4053, 4049], [4707, 8323, 7833, 7843], [1884, 1911, 2628, 2230, 2286, 1897, 2042, 2178, 2069, 1342, 2013, 2051, 2717, 2825], [1, 802, 760, 761, 834, 260, 268, 822, 4741, 4781, 297], [912, 1316, 4109, 6777, 4110, 5382, 3796, 2682, 5384, 1391, 4113, 6783, 987, 990, 5366, 5374], [1, 6968, 7534, 4917, 7531, 7538, 7379, 7380, 7381, 7383, 7535, 7535, 7485, 7541, 7290, 1], [1022, 1347, 1756, 1751, 1751, 1741, 1742, 1743, 1745, 1744, 1757, 1750], [1, 1192, 1195, 781, 782, 782, 782, 782], [1, 1183, 1184, 1194, 780, 785, 786, 1209, 1, 1209, 1187, 1207, 1195, 1196, 45, 45, 1178, 783, 1], [378, 400, 401, 406, 420, 398, 416, 384, 382, 404, 413, 387], [912, 1713, 7355, 3705, 3710, 3706, 6804, 1740, 3707, 3708, 1740, 6842], [1, 4944, 911, 4766, 4826, 87, 1], [1884, 2497, 2125, 2125, 2125, 2125, 2125, 1994, 2445, 2397, 2397, 1916, 2498, 1884], [912, 1641, 4041, 4043, 4036, 4038, 4048, 4040, 4045, 4053], [4707, 7835, 7854, 7855, 7856, 7836], [4702, 4703, 5668, 5623, 5669, 5670, 5671, 5672, 5673, 5602, 5601], [1, 7257, 7263, 890, 1292, 6980, 6980, 7295], [1, 4837, 8420, 94, 7037, 8418, 6972, 4853, 6929, 6929, 6928, 6928, 6928, 1299, 4801, 117, 6995], [912, 3642, 3643, 3927, 3927, 3012, 1359, 1108, 1108, 1108, 2021, 3687, 3936, 1546], [1884, 1923, 2025, 2158, 2120, 1929, 2522, 2728, 2508, 1897, 2130, 1934, 1779, 2007, 2013, 2532], [1, 328, 328, 724, 329, 331, 332, 701, 717, 704, 324, 272, 730, 720, 726, 712, 706, 727], [89, 7244, 1305, 882], [378, 381, 379, 400, 406, 398, 384, 413, 404, 397, 388], [1884, 1902, 2639, 1915, 2074, 2520, 7756, 2125, 2125, 2218, 1942], [912, 3953, 3938, 3939, 3567, 3466, 3942, 3943, 912, 3940, 3954, 3913, 3947, 3948, 3789], [1, 1272, 1273, 1284, 1281, 1282, 1283, 1274, 1275, 1276, 1279, 1278, 1285, 1277, 1277], [1, 328, 328, 724, 331, 331, 717, 701, 332, 704, 727, 726, 706, 712, 730, 272, 324, 89], [1, 1194, 1185, 780, 786, 1186, 1190, 1207, 1196, 45, 45, 1193, 1178, 1208, 783, 782, 89], [89, 1, 626, 627, 605, 606, 609, 615, 337, 66, 66, 1289, 7322], [1, 4795, 4794, 1296, 94, 1298, 4796, 633, 6951, 6928, 6928, 6928, 6929, 6929, 4800, 4801, 126], [8594, 8647, 8627, 8663, 9447, 8662, 8681, 8634, 8709, 8633, 8664, 8677, 8678, 8594], [4707, 7947, 7871, 7832, 4707, 7831, 4707, 7831], [1, 290, 238, 6963, 239, 241, 245, 7266, 244, 243, 249, 248, 247, 246, 9630, 6964], [1, 8061, 4857, 8073, 8046, 4861, 8051, 4864, 4863, 8033, 7258, 8043, 7031, 8040, 7028, 8074, 7032, 8070, 8048, 8032, 8038, 8045, 8035, 4859], [1, 1145, 1145, 1166, 1166, 1282, 6986, 8078, 4828, 1272, 1273, 4779, 1244, 1237, 1248, 1245]]\n",
      "\n",
      "Routes unique to LSTM model: 73 414\n",
      "Sample of LSTM-only routes: [[912, 3569, 3570, 3934, 3937, 938, 3577], [1022, 1520, 1632, 1554, 1556, 1332, 1619, 1338], [1, 185, 183, 184, 7285, 840, 840, 169, 189, 187, 188, 186, 139, 140, 861, 222, 1], [912, 3806, 4206, 4206, 3807, 4208, 4209, 3808, 4210, 4211, 4212], [1, 56, 795, 43, 8186, 50, 59, 49, 7693, 1223, 6434, 41, 6435], [1022, 1423, 1414, 1410, 1384, 1411, 1022], [912, 4228, 3333, 4492], [1, 8042, 8046, 8051, 4863, 8043, 7031, 8048, 8034, 8044, 8045, 4859, 8055], [1, 911, 4933, 4826, 4824, 809, 6197, 7766], [1, 781, 1192], [1, 4754, 4751, 4752, 4883, 4867, 4895, 4893, 4894, 4887, 4866, 4901, 4757, 4759], [912, 3640, 3641, 3682, 912], [1, 56, 795, 43, 43, 8186, 44, 6156, 1177, 49, 41], [1022, 1394, 1489, 1556, 1488, 1487, 1801, 1419], [1022, 1341, 1557, 1600, 1545], [1, 1119, 541, 1166, 1166, 1145, 1145, 1135, 1134, 1140, 1140, 1124, 542, 1141, 544, 1121, 1121, 1], [1, 760, 227, 803, 264, 315, 6196, 4951, 570, 536, 6197, 809, 533], [690, 837, 1], [1, 6137, 1221, 1231, 49, 1170, 1177], [912, 3407, 5330, 5331, 5199, 3776, 5299, 5299, 5299, 5200, 1670, 5201, 5207, 1631, 5332, 5333, 5333, 912], [1, 807, 185, 164, 7303, 171, 171, 171, 171, 171, 198, 209, 208, 207, 840, 133, 222], [912, 4413, 4129, 4130, 3564, 3563, 3561, 4355, 6664, 1357, 3796, 6665, 4262], [1, 522, 258, 258, 560, 526, 553, 551, 554, 591], [1, 12, 12, 1308, 1307, 1304, 1305], [1884, 1903, 1916, 2776, 2103, 1905, 2777, 2778, 2285, 2779], [1, 154, 194, 130, 145, 145, 145, 145, 145, 145, 145, 145, 145, 174, 174, 174, 173, 138, 150, 197, 199], [1022, 1561, 1562, 1563, 1564, 1635], [1022, 1399, 1383, 1391, 1022, 1414, 1578, 1660], [1, 4754, 4750, 4751, 4752, 4883, 4895, 4867, 4894, 4887, 4866, 4759], [1, 1119, 1132, 1132, 1133, 1134, 1115, 1113, 1114, 1146, 1136, 1121, 1138, 1122, 1123, 1126, 1], [1, 1272, 1273, 8077, 1281, 1283, 8078, 4828, 6986, 1, 1284], [912, 3670, 3671, 3671, 4590, 3673, 3674, 3677, 3678, 3679, 4588, 3680, 3681, 6614, 3676, 3683, 3682, 912], [1022, 1740, 1747, 1332, 1619, 1333, 1329, 1394], [912, 4228, 3333], [1884, 2773, 2013, 2012, 2774, 2051, 2775, 1998, 2455], [1022, 1523, 1524, 1022, 1521, 1551, 1606, 1504, 1711], [912, 4260, 3781, 3782, 3784, 3785, 3786, 1357, 3796, 3797, 4261, 4262, 4263], [1884, 2005, 1933, 2058, 2450, 2642, 3018, 7747, 1965], [4115, 4116, 4116], [912, 3606, 1713, 3710, 7355, 6804, 6805, 3359, 3616, 3615, 2320, 3364, 3727, 1810, 3336, 3335, 912], [1, 761, 760, 565, 805, 803, 263, 264], [912, 937, 2682, 3924, 3954, 3969, 3979, 3974, 3789, 3976], [1, 371, 690, 837, 1], [1, 6137, 1206, 69, 9274, 9281, 9281], [912, 3563, 4129, 3497, 6876, 3509, 991, 3513, 3907, 3604, 3591, 6636, 1022, 6638, 1326, 912], [1022, 1557, 1604], [1, 1, 210, 171, 171, 171, 171, 196, 213, 1262, 787, 222, 138, 7313], [1022, 7580, 7583, 955, 1469, 1716, 1386, 1022], [1022, 1341, 1341, 1342, 1022, 1401, 1581, 1545], [1, 1119, 1133, 1134, 1157, 1115, 1140, 542, 1120, 1121, 1138, 1122, 1123], [1, 1, 4905, 283, 286, 287, 277, 278], [912, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078], [1, 4867, 4884, 4869, 4870, 4871, 4868, 4875, 4876, 4878, 4879], [1, 4871, 4895, 4891, 4866, 4908, 4890, 4890, 1], [912, 3407, 3640, 4982, 4284, 4983, 4984, 4985, 3414, 2857, 3421, 3417], [1, 761, 4742, 760, 227, 805, 763, 803, 6184, 264, 1, 263], [1, 4838, 4823, 911, 902, 7767, 256, 4766, 4766, 4825, 4826, 4949, 4782, 809, 738, 759, 1], [912, 3781, 3782, 3785, 1470, 3786, 3783, 3816], [1884, 1909, 1942, 1932, 2549, 1916, 2266, 2039, 2181, 2042, 2178, 2020], [1, 238, 310, 311, 241, 309, 312], [1022, 1524, 1523, 1526], [1, 7315, 7314, 7316, 627, 627, 605, 1260, 613, 606, 609, 611], [8594, 9237, 9243, 9063, 9095, 9238], [1, 1119, 1133, 1135, 1134, 1115, 1113, 1114, 1140, 1146, 1151, 1125, 543, 1121, 1139, 1138, 1122, 1123, 1126], [912, 1096, 3429, 3429, 1097, 1098, 5348, 5350, 1099, 1100, 1100, 3645, 1101, 1103, 1104], [1, 4938, 4790, 1292, 7294, 6980, 6980, 7295], [1, 184, 183, 185, 165, 202, 189, 187, 164, 162, 198, 840], [1, 4846, 282, 318, 286, 277, 287], [912, 3469, 3468, 1082, 1080, 1085, 1089, 1086, 1087, 6836, 6890, 4339, 5405, 6891, 1723, 6897], [1, 4823, 911, 7767, 4766, 4825, 4826, 4824, 4827, 4782, 7764, 323], [1, 183, 185, 187, 189, 201, 139, 140, 171, 840, 861, 222, 1, 7309], [1022, 1334, 1315, 1022, 1357, 1335, 1336, 1633], [1, 802, 760, 4742, 562, 259, 803, 822, 268, 297, 6184]]\n",
      "414\n"
     ]
    }
   ],
   "source": [
    "ha_tp_routes = test_df_group_HA[test_df_group_HA['prediction_category'] == 'True Negative']['routes'].tolist()\n",
    "lstm_tp_routes = categorized_df[categorized_df['prediction_category'] == 'True Negative']['routes'].tolist()\n",
    "\n",
    "# ha_tp_routes, lstm_tp_routes\n",
    "print(len(ha_tp_routes), len(lstm_tp_routes))\n",
    "# # Convert lists to sets of tuples for comparison\n",
    "ha_tp_routes_set = set(tuple(route) for route in ha_tp_routes)\n",
    "lstm_tp_routes_set = set(tuple(route) for route in lstm_tp_routes)\n",
    "common_routes = ha_tp_routes_set.intersection(lstm_tp_routes_set)\n",
    "#\n",
    "# Find non-overlapping routes\n",
    "ha_only_routes = ha_tp_routes_set - lstm_tp_routes_set\n",
    "lstm_only_routes = lstm_tp_routes_set - ha_tp_routes_set\n",
    "\n",
    "\n",
    "# Convert back to lists for display\n",
    "common_routes = [list(route) for route in common_routes]\n",
    "ha_only_routes = [list(route) for route in ha_only_routes]\n",
    "lstm_only_routes = [list(route) for route in lstm_only_routes]\n",
    "\n",
    "print(\"Routes unique to HA model:\", len(ha_only_routes), len(common_routes))\n",
    "print(\"Sample of HA-only routes:\", ha_only_routes)\n",
    "\n",
    "print(\"\\nRoutes unique to LSTM model:\", len(lstm_only_routes), len(common_routes))\n",
    "print(\"Sample of LSTM-only routes:\", lstm_only_routes)\n",
    "print(len(common_routes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 249\n",
      "Routes unique to HA model: 76 194\n",
      "\n",
      "Routes unique to LSTM model: 55 194\n"
     ]
    }
   ],
   "source": [
    "def find_common_and_unique_routes(list1, list2):\n",
    "    \"\"\"\n",
    "    Find common routes and routes unique to each list without using sets.\n",
    "    Args:\n",
    "        list1, list2: Lists of routes where each route is a list\n",
    "    Returns:\n",
    "        common_routes: Routes that appear in both lists\n",
    "        list1_only: Routes unique to list1\n",
    "        list2_only: Routes unique to list2\n",
    "    \"\"\"\n",
    "    # Convert inner lists to tuples for comparison\n",
    "    list1_tuples = [tuple(route) for route in list1]\n",
    "    list2_tuples = [tuple(route) for route in list2]\n",
    "\n",
    "    # Find common routes\n",
    "    common_routes = []\n",
    "    for route in list1_tuples:\n",
    "        if route in list2_tuples:\n",
    "            common_routes.append(route)\n",
    "\n",
    "    # Find routes unique to list1\n",
    "    list1_only = []\n",
    "    for route in list1_tuples:\n",
    "        if route not in list2_tuples:\n",
    "            list1_only.append(route)\n",
    "\n",
    "    # Find routes unique to list2\n",
    "    list2_only = []\n",
    "    for route in list2_tuples:\n",
    "        if route not in list1_tuples:\n",
    "            list2_only.append(route)\n",
    "\n",
    "    # Convert results back to lists\n",
    "    common_routes = [list(route) for route in common_routes]\n",
    "    list1_only = [list(route) for route in list1_only]\n",
    "    list2_only = [list(route) for route in list2_only]\n",
    "\n",
    "    return common_routes, list1_only, list2_only\n",
    "\n",
    "# Get the routes lists\n",
    "ha_tp_routes = test_df_group_HA[test_df_group_HA['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "lstm_tp_routes = categorized_df[categorized_df['prediction_category'] == 'False Positive']['routes'].tolist()\n",
    "\n",
    "print(len(ha_tp_routes), len(lstm_tp_routes))\n",
    "\n",
    "# Find common and unique routes\n",
    "common_routes, ha_only_routes, lstm_only_routes = find_common_and_unique_routes(ha_tp_routes, lstm_tp_routes)\n",
    "\n",
    "print(\"Routes unique to HA model:\", len(ha_only_routes), len(common_routes))\n",
    "# print(\"Sample of HA-only routes:\", ha_only_routes)\n",
    "\n",
    "print(\"\\nRoutes unique to LSTM model:\", len(lstm_only_routes), len(common_routes))\n",
    "# print(\"Sample of LSTM-only routes:\", lstm_only_routes)\n",
    "# print(len(common_routes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get correct predictions from first model\n",
    "model1_correct = test_df_group_HA[\n",
    "    (test_df_group_HA['prediction_category'] == 'False Positive') |\n",
    "    (test_df_group_HA['prediction_category'] == 'False Negative')\n",
    "]\n",
    "\n",
    "# Get correct predictions from second model\n",
    "model2_correct = categorized_df[\n",
    "    (categorized_df['prediction_category'] == 'True Positive') |\n",
    "    (categorized_df['prediction_category'] == 'True Negative')\n",
    "]\n",
    "\n",
    "# Get the intersection (common indices between both)\n",
    "both_correct = model1_correct.index.intersection(model2_correct.index)\n",
    "len(both_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "route_str = str([912, 912, 4133, 4134])\n",
    "categorized_df[categorized_df['routes'].astype(str) == route_str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TP 52 636\n",
    "   73\n",
    "FP 74 193\n",
    "   55\n",
    "TN 55 414\n",
    "   73\n",
    "FN 73 142\n",
    "   52\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "CNN:\n",
    "1632: 793 label0,\n",
    "TP: 54 561 benchmark\n",
    "    75 561 model\n",
    "FP: 88 153 benchmark\n",
    "    49 153 model\n",
    "TN: 49 494 benchmark\n",
    "    86 494 model\n",
    "FN: 73 141 benchmark\n",
    "    53 141 model\n",
    "\n",
    "0.15\n",
    "TP 80 556\n",
    "   60 556\n",
    "FP: 112 149\n",
    "    36 149\n",
    "TN: 36 491\n",
    "    110 491\n",
    "FN: 60 156 benchmark\n",
    "    79 156 benchmark\n",
    "\n",
    "0.3\n",
    "TP: 45 567 benchmark\n",
    "    64 567 model\n",
    "FP: 82 167 benchmark\n",
    "    56 167 model\n",
    "TN: 55 505 benchmark\n",
    "    81 505 model\n",
    "FN: 64 155 benchmark\n",
    "    44 155 model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a = 561+494, b = 54+49, c = 75+86, d = 153+141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.895348837209302, 0.015180922344966777)\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating the mcnemar test\n",
    "from mlxtend.evaluate import mcnemar\n",
    "# define contingency table\n",
    "table = np.array([[1061, 149],\n",
    "\t\t [109, 337]])\n",
    "# calculate mcnemar test\n",
    "result = mcnemar(table)\n",
    "print(result)\n",
    "# summarize the finding\n",
    "# print('statistic=%.3f, p-value=%.10f' % (result.statistic, result.pvalue))\n",
    "# interpret the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_stat(stats, stat_name):\n",
    "    # Calculate mean for regression stats\n",
    "    arr = np.array([item[stat_name] for item in stats])\n",
    "    return arr.mean()\n",
    "print('mse:', get_mean_stat(stats, 'mse'))\n",
    "print('rmse:', get_mean_stat(stats, 'rmse'))\n",
    "print('mae:', get_mean_stat(stats, 'mae'))\n",
    "print('r2:', get_mean_stat(stats, 'r2'))\n",
    "\n",
    "# If you want to visualize the distribution of predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "for stat in stats:\n",
    "    plt.scatter(stat['y'], stat['y_pred'], alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted vs True Values')\n",
    "plt.show()\n",
    "\n",
    "# If you want to visualize the residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "for stat in stats:\n",
    "    residuals = np.array(stat['y_pred']) - np.array(stat['y'])\n",
    "    plt.scatter(stat['y'], residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
